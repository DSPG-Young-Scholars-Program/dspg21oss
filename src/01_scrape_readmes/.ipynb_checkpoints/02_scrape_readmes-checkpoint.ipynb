{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub README Extraction \n",
    "\n",
    "During this summer, the DSGP OSS 2021 team willbe classifying GitHub repositores into different software types. To do this, we will be extracting README files from all of the OSS repos (i.e. those with OSS licenses) and then developing NLP techniques to classify those repos. In this file, we document the extraction process for GitHub README files. \n",
    "\n",
    "First, we load our packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "# load packages \n",
    "import os\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "import string \n",
    "import json\n",
    "import base64\n",
    "import urllib.request\n",
    "import itertools \n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import time\n",
    "from functools import wraps\n",
    "import urllib.request\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "from retrying import retry\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will grab our data from the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the database, download data \n",
    "connection = pg.connect(host = 'postgis1', database = 'sdad', \n",
    "                        user = os.environ.get('db_user'), \n",
    "                        password = os.environ.get('db_pwd'))\n",
    "\n",
    "raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked where commits > 10000'''\n",
    "\n",
    "# convert to a dataframe, show how many missing we have (none)\n",
    "raw_slug_data = pd.read_sql_query(raw_slug_data, con=connection)\n",
    "raw_slug_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RichardLitt/standard-readme', '16:06:15')\n",
      "('uva-bi-sdad/oss-2020', '16:06:15')\n",
      "('brandonleekramer/diversity', '16:06:15')\n",
      "('facebook/react', '16:06:15')\n"
     ]
    }
   ],
   "source": [
    "batch = \"batch1\"\n",
    "\n",
    "slugs = raw_slug_data.slug.tolist()\n",
    "\n",
    "# exp multiplier that waits 30 seconds, then 30 secs + 30 secs, etc until 5 tries is over \n",
    "@retry(stop_max_attempt_number=5, wait_exponential_multiplier=30000, wait_exponential_max=30000) \n",
    "def scrape_slugs(slug):\n",
    "    ''' Scrapes slugs with multiple threads '''\n",
    "    url = f'https://github.com/{slug}#readme'\n",
    "    split_slugs = slug.split(\"/\")\n",
    "    login = split_slugs[0]\n",
    "    repo = split_slugs[1]\n",
    "    fullfilename = os.path.join('/project/class/bii_sdad_dspg/ncses_oss_2021/', f'readme_{login}_{repo}.txt')\n",
    "    urllib.request.urlretrieve(url, fullfilename)\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    return slug, current_time\n",
    "\n",
    "cores_available = multiprocessing.cpu_count() - 1\n",
    "pool = Pool(cores_available)\n",
    "\n",
    "logging_slugs = []\n",
    "logging_time = []\n",
    "for result in pool.imap_unordered(scrape_slugs, slugs):\n",
    "    logging_slugs.append(result[0])\n",
    "    logging_time.append(result[1])\n",
    "    logging_df = pd.DataFrame({'slug': logging_slugs, \"batch\": batch, 'time_scraped': logging_time}, columns=[\"slug\", \"batch\", \"time_scraped\"])\n",
    "    logging_df.to_csv('/project/class/bii_sdad_dspg/ncses_oss_2021/'+batch+'_log.csv', index=False)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished scraping: brandonleekramer/diversity\n",
      "Finished scraping: uva-bi-sdad/oss-2020\n",
      "Finished scraping: facebook/react\n",
      "Finished scraping: RichardLitt/standard-readme\n"
     ]
    }
   ],
   "source": [
    "slugs = [\"brandonleekramer/diversity\", \n",
    "         \"uva-bi-sdad/oss-2020\", \n",
    "         \"facebook/react\", \n",
    "         \"RichardLitt/standard-readme\"\n",
    "] \n",
    "\n",
    "\n",
    "\n",
    "slugs = [\"brandonleekramer/diversity\", \"uva-bi-sdad/oss-2020\", \"facebook/react\", \"RichardLitt/standard-readme\"] #test data \n",
    "#slugs = raw_slug_data.slug.tolist()\n",
    "\n",
    "#myPath = '/sfs/qumulo/qhome/kb7hp/git/oss-2020/src/09_repository-scraping/' \n",
    "myPath = '/project/class/bii_sdad_dspg/ncses_oss_2021/'\n",
    "\n",
    "for slug in slugs:\n",
    "    url = f'https://github.com/{slug}#readme'\n",
    "    split_slugs = slug.split(\"/\")\n",
    "    login = split_slugs[0]\n",
    "    repo = split_slugs[1]\n",
    "    fullfilename = os.path.join(myPath, f'readme_{login}_{repo}.txt')\n",
    "    urllib.request.urlretrieve(url, fullfilename)\n",
    "    print(f'Finished scraping: {login}/{repo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uva-bi-sdad/oss-2020'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to Crystal: \n",
    "\n",
    "The function above this note works for small-scale scraping but we need to add in the rate limit on API calls before we scale up. \n",
    "https://stackoverflow.com/questions/40748687/python-api-rate-limiting-how-to-limit-api-calls-globally\n",
    "\n",
    "We could also try to add in multiprocessing to speed things up. I'm not sure this link is the right one, but we can chat more about that.\n",
    "https://stackoverflow.com/questions/54858979/how-to-use-multiprocessing-with-requests-module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>readme_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brandonleekramer/diversity</td>\n",
       "      <td>The Rise of Diversity and Population Terminolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RichardLitt/standard-readme</td>\n",
       "      <td>Standard Readme\\n\\nA standard style for README...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/react</td>\n",
       "      <td>React ·    \\nReact is a JavaScript library for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uva-bi-sdad/oss-2020</td>\n",
       "      <td>UVA-BII Open Source Software 2020-21\\nAs of: 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          slug  \\\n",
       "0   brandonleekramer/diversity   \n",
       "1  RichardLitt/standard-readme   \n",
       "2               facebook/react   \n",
       "3         uva-bi-sdad/oss-2020   \n",
       "\n",
       "                                         readme_text  \n",
       "0  The Rise of Diversity and Population Terminolo...  \n",
       "1  Standard Readme\\n\\nA standard style for README...  \n",
       "2  React ·    \\nReact is a JavaScript library for...  \n",
       "3  UVA-BII Open Source Software 2020-21\\nAs of: 0...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_name = []\n",
    "readme_text = [] \n",
    "for filename in os.listdir(myPath):\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join(myPath, filename)) as f:\n",
    "            content = f.read()\n",
    "            soup = BeautifulSoup(content, 'html.parser')\n",
    "            clean_html = ''.join(soup.article.findAll(text=True))\n",
    "            repo_name.append(filename)\n",
    "            readme_text.append(clean_html)\n",
    "            df = pd.DataFrame({'slug': repo_name, 'readme_text': readme_text}, columns=[\"slug\", \"readme_text\"])\n",
    "            df['slug'] = df['slug'].str.replace('readme_','')\n",
    "            df['slug'] = df['slug'].str.replace('.txt','')\n",
    "            # this works because slugs can't have underscores\n",
    "            df['slug'] = df['slug'].str.replace('_','/') \n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write this to the database now... \n",
    "\n",
    "Try this: https://medium.com/analytics-vidhya/part-3-5-pandas-dataframe-to-postgresql-using-python-d3bc41fcf39 \n",
    "https://pybay.com/site_media/slides/raymond2017-keynote/process.html\n",
    "https://github.com/rholder/retrying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brandon_env",
   "language": "python",
   "name": "brandon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
