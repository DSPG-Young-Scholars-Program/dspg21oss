{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap repo stats using PyGitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Crystal Zang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilized GitHub access tokens (PAT) to scrape GitHub repository statistics such as stargazers, watchers, forks, and topics. One PAT would scrape at a rate of 5000 repositories per hour. Utilizing 36 PATs we would scrape 10,288,063 repositories in about 663 hours at a rate of 15,514 repositories per hour. Note that if a repository do not exist(being deleted), it won't be saved to our final dataset. And we did not use multiprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warnings\n",
    "You should not commit any access topen to GitHub, which would result in access token being revoked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages \n",
    "import os\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "import string \n",
    "import json\n",
    "import base64\n",
    "import urllib.request\n",
    "import itertools \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from github import Github, RateLimitExceededException, BadCredentialsException, BadAttributeException, GithubException, UnknownObjectException, BadUserAgentException\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "import multiprocessing\n",
    "#from multiprocessing.pool import ThreadPool as Pool\n",
    "from multiprocessing import Pool, freeze_support\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the repo slugs that we plan to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id      spdx                     slug  \\\n",
      "0  MDEwOlJlcG9zaXRvcnkzMDgyMjMzNw==       MIT      WenchaoD/FSCalendar   \n",
      "1  MDEwOlJlcG9zaXRvcnk5Mjc0MDI1Ng==   GPL-3.0  halvors/Nuclear-Physics   \n",
      "2  MDEwOlJlcG9zaXRvcnkyODUyODU5ODU=       MIT         LCYforever/lqt5_   \n",
      "3  MDEwOlJlcG9zaXRvcnkxNjg5MzQ5MDA=  AGPL-3.0  AragonBlack/fundraising   \n",
      "4  MDEwOlJlcG9zaXRvcnk3MjI2MzgwMQ==       MIT           guyellis/learn   \n",
      "\n",
      "            createdat                                        description  \\\n",
      "0 2015-02-15 08:43:09  A fully customizable iOS calendar library, com...   \n",
      "1 2017-05-29 12:59:30  Nuclear Physics is a mod that brings in realis...   \n",
      "2 2020-08-05 12:47:19                                               None   \n",
      "3 2019-02-03 10:47:17    Fundraising apps suite for Aragon organizations   \n",
      "4 2016-10-29 03:56:49               Math exercises for kids aged 5 to 12   \n",
      "\n",
      "  primarylanguage                                        branch  commits  \\\n",
      "0     Objective-C  MDM6UmVmMzA4MjIzMzc6cmVmcy9oZWFkcy9tYXN0ZXI=      799   \n",
      "1            Java  MDM6UmVmOTI3NDAyNTY6cmVmcy9oZWFkcy8xLjEwLjI=      799   \n",
      "2             C++      MDM6UmVmMjg1Mjg1OTg1OnJlZnMvaGVhZHMvcXQ1      799   \n",
      "3      JavaScript  MDM6UmVmMTY4OTM0OTAwOnJlZnMvaGVhZHMvbWFzdGVy      799   \n",
      "4      JavaScript  MDM6UmVmNzIyNjM4MDE6cmVmcy9oZWFkcy9tYXN0ZXI=      799   \n",
      "\n",
      "                 asof status  \n",
      "0 2021-01-03 16:20:21   Init  \n",
      "1 2021-01-03 17:01:32   Init  \n",
      "2 2021-01-03 18:00:30   Init  \n",
      "3 2021-01-03 14:44:02   Init  \n",
      "4 2021-01-03 17:47:36   Init  \n",
      "(16734, 10)\n",
      "id                    0\n",
      "spdx                  0\n",
      "slug                  0\n",
      "createdat             0\n",
      "description        7247\n",
      "primarylanguage     166\n",
      "branch                0\n",
      "commits               0\n",
      "asof                  0\n",
      "status                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#os.environ['db_user'] = ''\n",
    "#os.environ['db_pwd'] = ''\n",
    "\n",
    "# connect to the database, download data, limit to repos with at least 20,000 commits?\n",
    "connection = pg.connect(host = 'postgis1', database = 'sdad', \n",
    "                        user = os.environ.get('db_user'), \n",
    "                        password = os.environ.get('db_pwd'))\n",
    "\n",
    "raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked WHERE (commits BETWEEN '700' AND '800')'''\n",
    "#raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked WHERE commits < 1000'''\n",
    "\n",
    "# convert to a dataframe, show how many missing we have (none)\n",
    "raw_slug_data = pd.read_sql_query(raw_slug_data, con=connection)\n",
    "\n",
    "connection.close()\n",
    "\n",
    "\n",
    "print(raw_slug_data.head())\n",
    "print(raw_slug_data.shape)\n",
    "print(raw_slug_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_slug_data = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/crystal_to_scrape_0712.csv') #import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16734\n",
      "WenchaoD/FSCalendar phil-el/phetools\n"
     ]
    }
   ],
   "source": [
    "#get rid of leading and ending space, save slugs to a list\n",
    "raw_slugs = raw_slug_data[\"slug\"].tolist()\n",
    "slugs = []\n",
    "for s in raw_slugs:\n",
    "    slugs.append(s.strip())  \n",
    "print(len(slugs))\n",
    "print(slugs[0], slugs[len(slugs)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Access Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['db_user'] = ''\n",
    "#os.environ['db_pwd'] = ''\n",
    "\n",
    "# connect to the database, download data, limit to repos with at least 20,000 commits?\n",
    "connection = pg.connect(host = 'postgis1', database = 'sdad', \n",
    "                        user = os.environ.get('db_user'), \n",
    "                        password = os.environ.get('db_pwd'))\n",
    "\n",
    "#PATs access token, saved as a dataframe\n",
    "github_pats = '''SELECT * FROM gh_2007_2020.pats_update'''\n",
    "github_pats = pd.read_sql_query(github_pats, con=connection)\n",
    "\n",
    "#PATs access token, saved as a list\n",
    "access_tokens = github_pats[\"token\"]\n",
    "\n",
    "#number of tokens available for use, a numeric value\n",
    "num_token = '''SELECT COUNT(*) FROM gh_2007_2020.pats_update'''\n",
    "num_token = pd.read_sql_query(num_token, con=connection)\n",
    "num_token=num_token.iloc[0]['count']\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index ranges from 0 to maximum number of PATs available\n",
    "def get_access_token(github_pat_index):\n",
    "    if github_pat_index < num_token:\n",
    "       # print(\"Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "        return github_pats.token[github_pat_index]\n",
    "    else:\n",
    "        print(\"token exceed limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(access_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping function, not using any multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_repo_stats(github_pat_index, slugs):\n",
    "    df_repo_stats = pd.DataFrame()\n",
    "    for slug in slugs:\n",
    "        if github_pat_index >= len(access_tokens):\n",
    "            github_pat_index -= len(access_tokens)\n",
    "            print(\"***Pat access token exceed limit, restart access token loop with #\", github_pat_index)\n",
    "        while github_pat_index < len(access_tokens):\n",
    "            try:\n",
    "                access_token = get_access_token(github_pat_index)\n",
    "                #print(\"Scrapping --\", slug,\". Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "                #if false, retry until true, max number of retry is 20 times\n",
    "                g = Github(access_token, retry = 20, timeout = 15)\n",
    "                repo = g.get_repo(slug)\n",
    "                df_repo_stats = df_repo_stats.append({\n",
    "                    \"slug\": slug,\n",
    "                    'stars': repo.stargazers_count,\n",
    "                    'watchers': repo.subscribers_count,\n",
    "                    'forks': repo.forks_count,\n",
    "                    'topics': repo.get_topics()\n",
    "                }, ignore_index = True)\n",
    "            except RateLimitExceededException as e:\n",
    "                print(e.status)\n",
    "                print('Rate limit exceeded --', slug, \", using access token #\", github_pat_index)\n",
    "                print(\"Current time:\", datetime.datetime.now())\n",
    "                #time.sleep(300)\n",
    "                github_pat_index+=1\n",
    "                print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "                break\n",
    "            except BadCredentialsException as e:\n",
    "                print(e.status)\n",
    "                print('Bad credentials exception --', slug, \", using access token #\", github_pat_index)\n",
    "                print(\"Current time:\", datetime.datetime.now())\n",
    "                github_pat_index+=1\n",
    "                print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "                break\n",
    "            except UnknownObjectException as e:\n",
    "                print(e.status)\n",
    "                print('Unknown object exception --', slug)\n",
    "                break\n",
    "            except GithubException as e:\n",
    "                print(e.status)\n",
    "                print('General exception --', slug)\n",
    "                break\n",
    "            except r.exceptions.ConnectionError as e:\n",
    "                print('Retries limit exceeded --', slug)\n",
    "                print(str(e))\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            except r.exceptions.Timeout as e:\n",
    "                print('Time out exception --', slug)\n",
    "                print(str(e))\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            break\n",
    "    return df_repo_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16734"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start scraping:\", start_time)\n",
    "df_repo_stats = pull_repo_stats(0, slugs) #specify the index of pat you want use to start scraping\n",
    "end_time =  datetime.datetime.now()\n",
    "print(\"Finished scraping\", len(df_repo_stats), \"of\", len(slugs), \"records at\", end_time)\n",
    "print(\"It took\", end_time-start_time, \"to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forks</th>\n",
       "      <th>slug</th>\n",
       "      <th>stars</th>\n",
       "      <th>topics</th>\n",
       "      <th>watchers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>petejohanson/hyena</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>stuartwan/imlazyone.github.io</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311.0</td>\n",
       "      <td>keycloak/keycloak-nodejs-connect</td>\n",
       "      <td>402.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155.0</td>\n",
       "      <td>TommyLemon/APIAuto</td>\n",
       "      <td>910.0</td>\n",
       "      <td>[apijson, vuejs2, document-database, autotesti...</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245.0</td>\n",
       "      <td>seg/2016-ml-contest</td>\n",
       "      <td>144.0</td>\n",
       "      <td>[machine-learning, data-science, geoscience, c...</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   forks                              slug  stars  \\\n",
       "0    1.0                petejohanson/hyena    1.0   \n",
       "1    0.0     stuartwan/imlazyone.github.io    0.0   \n",
       "2  311.0  keycloak/keycloak-nodejs-connect  402.0   \n",
       "3  155.0                TommyLemon/APIAuto  910.0   \n",
       "4  245.0               seg/2016-ml-contest  144.0   \n",
       "\n",
       "                                              topics  watchers  \n",
       "0                                                 []       1.0  \n",
       "1                                                 []       1.0  \n",
       "2                                                 []      26.0  \n",
       "3  [apijson, vuejs2, document-database, autotesti...      26.0  \n",
       "4  [machine-learning, data-science, geoscience, c...      30.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the file and check\n",
    "df_repo_stats.head()\n",
    "#print(df_repo_stats)\n",
    "#print(df_repo_stats.isna().sum())\n",
    "#print(df_repo_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save csv\n",
    "#df_repo_stats.to_csv(r'/home/zz3hs/git/dspg21oss/data/dspg21oss/new_repo_stats_0712_3.csv', index = False)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crystal]",
   "language": "python",
   "name": "conda-env-.conda-crystal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
