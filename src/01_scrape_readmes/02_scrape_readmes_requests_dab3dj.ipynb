{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px\" align=\"center\"> <b> Scaping GitHub READMEs </b> </div>\n",
    "\n",
    "<div style=\"font-size:18px\" align=\"center\"> <b> Brandon Kramer, UVA Biocomplexity Institute, OSS DSPG 2021 </b> </div>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Overview  \n",
    "\n",
    "In this notebook, we have developed a function for scraping GitHub READMEs in order to classify repositories into different types of software projects. \n",
    "\n",
    "The pipeline is setup with the following steps: \n",
    "\n",
    "1. Loading all of the packages \n",
    "\n",
    "2. Calling a function that scrapes the READMEs \n",
    "\n",
    "3. Loading the repositories from PostgreSQL as a DataFrame \n",
    "\n",
    "4. Cross-referencing the repos against the scraped data \n",
    "\n",
    "5. Scraping the repos using multiprocessing \n",
    "\n",
    "6. Checking the data that was scraped \n",
    "\n",
    "### Load Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "# for pulling/manipulating data \n",
    "import os \n",
    "import glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# for web scraping \n",
    "import json \n",
    "import lxml\n",
    "import requests \n",
    "from requests.auth import HTTPBasicAuth\n",
    "from bs4 import BeautifulSoup\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "print(\"ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Functions\n",
    "\n",
    "To use the `scrape_readmes()` function, you first need to set the username and personal acccess token (PAT) that you create on GitHub. While you can run it without this information but having no PAT means you can only make 50 calls an hour compared to about 5,000. It helps if you have several PATs to help in this process, especially since this function takes only a few moments to make 5,000 calls after the multiprocessing is incorporated. In this pipeline, we are calling the usernames and PATs from a table in PostgreSQL that looks like this: \n",
    "\n",
    "|    login    |   token  | \n",
    "|    :---:    |  :----:  |     \n",
    "|  username1  |   PAT1   | \n",
    "|  username2  |   PAT2   | \n",
    "|  etc.  |   etc.   | \n",
    "\n",
    "Once the username and PAT are passed into the authetication fields, `requests` will connect to the GitHub repository of all the slugs you feed it. We have designed the function to throw errors for all issues it encounters unless it gets a 404 error (i.e. no README available), as this usually means that the repo or README has been deleted, never existed, and/or is no longer available for some reason. Unfortunately, the way that GitHub's API is setup seems to require two calls to get the README: one to get the JSON with the README location and another to decode the content. We have a `@sleep_and_retry` decorator to deal with this if we setup a `slurm` for each PAT, but using it here in the notebook means that you will just want to wait for the threshold to be hit and then move onto the next PAT. While we plan to continue working on this function to minimize the number of calls, this process will allow us to get some preliminary data for classification in the short-term. \n",
    "\n",
    "At the end of this chunk, you will also see the `filter_scraped_readmes()` function that filters scraped READMEs. Basically, you just feed this function your original data and then it filters out slugs that have already been scraped based on the local CSV that has that information. \n",
    "\n",
    "**NOTE: Before running this cell, you need to set the** `github_pat_index`. **Changing this parameter provides access to 36 different PATs.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started scraping\n",
      "404 error on cjbd/src\n",
      "Finished scraping\n"
     ]
    }
   ],
   "source": [
    "# set this parameter to a number between 0 and 35 \n",
    "# pats #7, #14. #19, #25 seem to be setup wrong or have been removed \n",
    "github_pat_index = 20\n",
    "\n",
    "# set the environment variables with your username and github personal access token here \n",
    "# connect to the database, download data \n",
    "connection = pg.connect(host = 'postgis1', database = 'sdad', \n",
    "                        user = os.environ.get('db_user'), \n",
    "                        password = os.environ.get('db_pwd'))\n",
    "github_pats = '''SELECT * FROM gh_2007_2020.pats'''\n",
    "github_pats = pd.read_sql_query(github_pats, con=connection)\n",
    "connection.close()\n",
    "github_username = github_pats.login[github_pat_index]\n",
    "github_token = github_pats.token[github_pat_index]\n",
    "\n",
    "# os.environ['GITHUB_USERNAME'] = ''\n",
    "# os.environ['GITHUB_TOKEN'] = ''\n",
    "# github_username = os.environ.get(\"GITHUB_USERNAME\")\n",
    "# github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "\n",
    "# can only make 2500 calls per hour \n",
    "# because the function calls twice each time \n",
    "@sleep_and_retry\n",
    "@limits(calls=2500, period=3600)\n",
    "def scrape_readmes(slug):\n",
    "    \n",
    "    while True:\n",
    "        try: \n",
    "            # define url based on the slug \n",
    "            url = f'https://api.github.com/repos/{slug}/readme'\n",
    "            response = requests.get(url, auth=(github_username, github_token))\n",
    "            response_code = response.status_code\n",
    "            \n",
    "            if response_code == 404: \n",
    "                print(f\"404 error on {slug}\")\n",
    "                readme_string = \"404 ERROR - NO README\"\n",
    "                now = datetime.now()\n",
    "                current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                return slug, readme_string, current_time, \"Done\"\n",
    "            \n",
    "            # can i build in a response_code == 403 continue onto the next PAT in the PAT for loop \n",
    "            \n",
    "        except KeyError:\n",
    "            print(\"Key error for: \" + slug, flush=True)\n",
    "            break\n",
    "        \n",
    "        except requests.exceptions.HTTPError as http_error:\n",
    "            print (\"HTTP Error:\", http_error)\n",
    "            raise SystemExit(http_error)\n",
    "            break\n",
    "            \n",
    "        except requests.exceptions.ConnectionError as connection_error:\n",
    "            print (\"Error Connecting:\", connection_error)\n",
    "            raise SystemExit(connection_error)\n",
    "            break \n",
    "        \n",
    "        except requests.exceptions.TooManyRedirects as toomany_requests:\n",
    "            print (\"Too Many Requests:\", toomany_requests)\n",
    "            raise SystemExit(toomany_requests)\n",
    "            break\n",
    "                \n",
    "        except requests.exceptions.Timeout as timeout_error:\n",
    "            print (\"Timeout Error:\", timeout_error)\n",
    "            raise SystemExit(timeout_error)\n",
    "            break\n",
    "        \n",
    "        except requests.exceptions.RequestException as request_exception_error:\n",
    "            print (\"Oops, Some Other Error:\", request_exception_error)\n",
    "            raise SystemExit(request_exception_error)\n",
    "            break \n",
    "            \n",
    "        html_content = response.content\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        site_json=json.loads(soup.text)\n",
    "        readme_link = site_json['download_url']\n",
    "        \n",
    "        while True:\n",
    "            try: \n",
    "                readme_response = requests.get(readme_link, auth=(github_username, github_token))\n",
    "                readme_response_code = readme_response.status_code\n",
    "                \n",
    "            except requests.exceptions.HTTPError as http_error:\n",
    "                print (\"HTTP Error:\", http_error)\n",
    "                raise SystemExit(http_error)\n",
    "                break\n",
    "            \n",
    "            except requests.exceptions.ConnectionError as connection_error:\n",
    "                print (\"Error Connecting:\", connection_error)\n",
    "                raise SystemExit(connection_error)\n",
    "                break\n",
    "            \n",
    "            except requests.exceptions.TooManyRedirects as toomany_requests:\n",
    "                print (\"Too Many Requests:\", toomany_requests)\n",
    "                raise SystemExit(toomany_requests)\n",
    "                break \n",
    "        \n",
    "            except requests.exceptions.Timeout as timeout_error:\n",
    "                print (\"Timeout Error:\", timeout_error)\n",
    "                raise SystemExit(timeout_error)\n",
    "                break\n",
    "        \n",
    "            except requests.exceptions.RequestException as request_exception_error:\n",
    "                print (\"Oops, Some Other Error:\", request_exception_error)\n",
    "                raise SystemExit(request_exception_error)\n",
    "                break  \n",
    "    \n",
    "            # pull the content out of the readme \n",
    "            readme_content = readme_response.content\n",
    "            readme_soup = BeautifulSoup(readme_content, 'html.parser')\n",
    "            readme_string = str(readme_soup)\n",
    "    \n",
    "            #give us the the timing and status \n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            #print(readme_string)\n",
    "            return slug, readme_string, current_time, \"Done\"\n",
    "        \n",
    "def filter_scraped_readmes(original_data): \n",
    "    ''' \n",
    "    Function ingests repos data and filters out already scraped data from local csv \n",
    "    '''\n",
    "    \n",
    "    # ingests local csv data and converts it to a list \n",
    "    os.chdir('/project/class/bii_sdad_dspg/ncses_oss_2021/requests_scrape/')\n",
    "    all_filenames = [i for i in glob.glob('*.csv')]\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "    combined_csv = combined_csv[combined_csv['status'] == 'Done']\n",
    "    scraped_slugs_list = combined_csv['slug'].tolist()\n",
    "    \n",
    "    # filters out all of the scraped slugs from the original_data \n",
    "    filtered_slugs = ~raw_slug_data.slug.isin(scraped_slugs_list)\n",
    "    filtered_slugs = raw_slug_data[filtered_slugs]\n",
    "    \n",
    "    # provides the output of current slug count and number of slugs filtered \n",
    "    new_slug_count = filtered_slugs['slug'].count()\n",
    "    slug_count_diff = raw_slug_data['slug'].count() - filtered_slugs['slug'].count()\n",
    "    print(\"Current data has\", new_slug_count, \"entries (filtered\", slug_count_diff, \"from input data)\")\n",
    "    return filtered_slugs\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Started scraping\")\n",
    "    scrape_readmes(slug = 'cjbd/src')\n",
    "    print(\"Finished scraping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting the Repo Slugs from the Database \n",
    "\n",
    "Here, we ingested the repository data from PostgreSQL. To pull from different subsets of the data, you can change the range of the commits clause in the `SQL` code. Even if you pull from the same range as someone else already has, the next step of the pipeline is cross-referencing which READMEs have already been scraped and then removing from slugs from the dataset. I have also added a clause to remove all of the repos with an 'Init' status, as their commits data have not yet been scraped and they seem to missing in some systematic way. For now, we are just ignoring them to deal with the majority of valid repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>spdx</th>\n",
       "      <th>slug</th>\n",
       "      <th>createdat</th>\n",
       "      <th>description</th>\n",
       "      <th>primarylanguage</th>\n",
       "      <th>branch</th>\n",
       "      <th>commits</th>\n",
       "      <th>asof</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk4NTk0MjE4NQ==</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>crain/accounting</td>\n",
       "      <td>2017-03-23 11:29:26</td>\n",
       "      <td>Microservice for managing accounts, ledgers, a...</td>\n",
       "      <td>Java</td>\n",
       "      <td>MDM6UmVmODU5NDIxODU6cmVmcy9oZWFkcy9kZXZlbG9w</td>\n",
       "      <td>105</td>\n",
       "      <td>2021-01-03 13:53:22</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkyNTMzODA2OA==</td>\n",
       "      <td>MIT</td>\n",
       "      <td>yanhaijing/data.js</td>\n",
       "      <td>2014-10-17 04:23:00</td>\n",
       "      <td>data.js 是带有消息通知的数据中心，我称其为会说话的数据。旨在让编程变得简单，世界变得美好。</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>MDM6UmVmMjUzMzgwNjg6cmVmcy9oZWFkcy9tYXN0ZXI=</td>\n",
       "      <td>105</td>\n",
       "      <td>2021-01-03 14:18:29</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkyMzc4MDg1NTQ=</td>\n",
       "      <td>MIT</td>\n",
       "      <td>kituyiharry/gatsby-starter-blog-theme</td>\n",
       "      <td>2020-02-02 17:30:53</td>\n",
       "      <td>None</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>MDM6UmVmMjM3ODA4NTU0OnJlZnMvaGVhZHMvbWFzdGVy</td>\n",
       "      <td>105</td>\n",
       "      <td>2021-01-03 15:47:44</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnkxNjc4MDQ2NDQ=</td>\n",
       "      <td>MIT</td>\n",
       "      <td>cancit/teyit.link</td>\n",
       "      <td>2019-01-27 12:10:11</td>\n",
       "      <td>None</td>\n",
       "      <td>Go</td>\n",
       "      <td>MDM6UmVmMTY3ODA0NjQ0OnJlZnMvaGVhZHMvbWFzdGVy</td>\n",
       "      <td>105</td>\n",
       "      <td>2021-01-04 04:43:20</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDEwOlJlcG9zaXRvcnk5NjE1OTkyOA==</td>\n",
       "      <td>MIT</td>\n",
       "      <td>temiooo/PostIt-Application</td>\n",
       "      <td>2017-07-04 00:24:29</td>\n",
       "      <td>An application that allows users to create gro...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>MDM6UmVmOTYxNTk5Mjg6cmVmcy9oZWFkcy9EZXZlbG9w</td>\n",
       "      <td>105</td>\n",
       "      <td>2021-01-03 18:06:24</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id        spdx  \\\n",
       "0  MDEwOlJlcG9zaXRvcnk4NTk0MjE4NQ==  Apache-2.0   \n",
       "1  MDEwOlJlcG9zaXRvcnkyNTMzODA2OA==         MIT   \n",
       "2  MDEwOlJlcG9zaXRvcnkyMzc4MDg1NTQ=         MIT   \n",
       "3  MDEwOlJlcG9zaXRvcnkxNjc4MDQ2NDQ=         MIT   \n",
       "4  MDEwOlJlcG9zaXRvcnk5NjE1OTkyOA==         MIT   \n",
       "\n",
       "                                    slug           createdat  \\\n",
       "0                       crain/accounting 2017-03-23 11:29:26   \n",
       "1                     yanhaijing/data.js 2014-10-17 04:23:00   \n",
       "2  kituyiharry/gatsby-starter-blog-theme 2020-02-02 17:30:53   \n",
       "3                      cancit/teyit.link 2019-01-27 12:10:11   \n",
       "4             temiooo/PostIt-Application 2017-07-04 00:24:29   \n",
       "\n",
       "                                         description primarylanguage  \\\n",
       "0  Microservice for managing accounts, ledgers, a...            Java   \n",
       "1  data.js 是带有消息通知的数据中心，我称其为会说话的数据。旨在让编程变得简单，世界变得美好。      JavaScript   \n",
       "2                                               None      JavaScript   \n",
       "3                                               None              Go   \n",
       "4  An application that allows users to create gro...      JavaScript   \n",
       "\n",
       "                                         branch  commits                asof  \\\n",
       "0  MDM6UmVmODU5NDIxODU6cmVmcy9oZWFkcy9kZXZlbG9w      105 2021-01-03 13:53:22   \n",
       "1  MDM6UmVmMjUzMzgwNjg6cmVmcy9oZWFkcy9tYXN0ZXI=      105 2021-01-03 14:18:29   \n",
       "2  MDM6UmVmMjM3ODA4NTU0OnJlZnMvaGVhZHMvbWFzdGVy      105 2021-01-03 15:47:44   \n",
       "3  MDM6UmVmMTY3ODA0NjQ0OnJlZnMvaGVhZHMvbWFzdGVy      105 2021-01-04 04:43:20   \n",
       "4  MDM6UmVmOTYxNTk5Mjg6cmVmcy9oZWFkcy9EZXZlbG9w      105 2021-01-03 18:06:24   \n",
       "\n",
       "  status  \n",
       "0   Done  \n",
       "1   Done  \n",
       "2   Done  \n",
       "3   Done  \n",
       "4   Done  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to the database, download data \n",
    "connection = pg.connect(host = 'postgis1', database = 'sdad', \n",
    "                        user = os.environ.get('db_user'), \n",
    "                        password = os.environ.get('db_pwd'))\n",
    "\n",
    "raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked where commits < 106 AND commits > 100 AND status != 'Init' '''\n",
    "\n",
    "# convert to a dataframe, show how many missing we have (none)\n",
    "raw_slug_data = pd.read_sql_query(raw_slug_data, con=connection)\n",
    "raw_slug_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Counts \n",
    "\n",
    "Before running the function, you want to compare the original table that you just pulled from the database and the local CSV files that are keeping track of the already downloaded data. The first cell below gives you the count for the original table and the next cell pulls in all of the CSVs, concatenates them, and then gives the count of how many more slugs need to be scraped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27976"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_slug_data['slug'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current data has 19755 entries (filtered 8221 from input data)\n"
     ]
    }
   ],
   "source": [
    "new_slugs = filter_scraped_readmes(original_data=raw_slug_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the READMEs \n",
    "\n",
    "This chunk of code does a few things. First, it sets the `batch_name` to both keep track of which batch of data we are collecting and to name the output files with the appropriate name. This MUST be done before you run the code chunk. Second, the code sets up multiprocessing to draw from multiple cores. Third, the code converts the DataFrame into a list to feed the slugs into the for loop. Lastly, we feed all the slugs to the function as a for loop and it downloads the data into our project folder. \n",
    "\n",
    "**NOTE: Before running this cell, set the** `batch_name` **variable. Changing this variable will tell us which download batch the data was collected during and then save the CSV with that batch name.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404 error on leewujung/rousettus_bp\n",
      "404 error on saai/codingbitch\n",
      "404 error on emergenetwork/etherboy-core\n",
      "404 error on rizkiramadhan2/antarpulau\n",
      "404 error on mozama/AG\n",
      "404 error on jdaigle/jdaigle.github.io\n",
      "404 error on E-L-N-A/ELNA\n",
      "404 error on layd/wordsearch-android\n",
      "404 error on hrgdavor/java-hipster-sql\n",
      "404 error on BastyZ/Subastas_nSystem\n",
      "404 error on serlosan/serlosan.github.io\n",
      "404 error on fdabl/fdabl.github.io\n",
      "404 error on fvendrameto/Databases-Final-Project\n",
      "404 error on xbib/catalog\n",
      "404 error on DrenfongWong/x509-ada\n",
      "404 error on darrowco/z76-Docs\n",
      "404 error on tronixworkshop/tronixworkshop.github.io\n",
      "404 error on cvast/cvast-arches\n",
      "404 error on LaunchCoderGirlSTL/Data-Analysis-Learning-Track\n",
      "404 error on bmaupin/bmaupin.github.io\n",
      "404 error on AshtrayBroom/ashbloom\n",
      "404 error on selfhostedworks/openmappr\n",
      "404 error on zeddee/nsdmdh-src\n",
      "404 error on Jaruso/Maple_Tycoon\n",
      "404 error on SENERGY-Platform/smart-meter-connector\n",
      "404 error on cronfy/experience\n",
      "404 error on Steven-Chavez/CourseWork-AssociatesDegree\n",
      "404 error on Cimsolutions2019/Frontend\n",
      "404 error on BenedictC/BCOObjectStore\n",
      "404 error on ecorov/ecorov.github.io\n",
      "404 error on lukevandekieft/appsync_tutorial\n",
      "404 error on ieasb/ieasb.github.io\n",
      "404 error on yzylovepmn/YDrawing2D\n",
      "404 error on tehshin/bestoftheworst\n",
      "404 error on kallangerard/rmshelper\n",
      "404 error on aniabrown/QuEST_Performance404 error on wahern/luapath\n",
      "\n",
      "404 error on KoTiX/movieplayer_film\n",
      "404 error on latex-projects/ProjectTemplate\n",
      "404 error on veragodman/-\n",
      "404 error on ravenblu/ravenblu.github.io\n",
      "404 error on andrzejgorski/social_network_graph_analysis\n",
      "404 error on FLS-Wiesbaden/vplanUploader\n",
      "404 error on alexpear/commander\n",
      "404 error on jammaloo/tamarafreeman.ca\n",
      "404 error on mtomai/RevisionControlForImages\n",
      "404 error on koryagin2006/GB_Course_Database\n",
      "404 error on bruun-rasmussen/mail-util\n",
      "404 error on kakaLQY/config\n",
      "404 error on mikewubox/V2Ray_ws-tls_bash_onekey\n",
      "404 error on JohnOliver23/activities-of-the-second-period\n",
      "404 error on discferret/magpie\n",
      "404 error on ecrampton1/MspPeripheralmm\n",
      "404 error on RussbellGutierrez/KTransporte\n",
      "404 error on gamma-omg/libnes\n",
      "404 error on Quabynah-Codelabs/ug-congregation\n",
      "404 error on MyMiniFactory/3DPrintingMeshRepair\n",
      "404 error on maciejken/node-express-postgres\n",
      "404 error on hychul/zerone-android-example\n",
      "404 error on TrueC-D/Event-Space\n",
      "404 error on alex-clay/Brutal-Bunnyhop\n",
      "404 error on theAlidiary/theAlidiary.github.io\n",
      "404 error on 4oi/Nest-API\n",
      "404 error on felipeguilhermefs/dotfiles\n",
      "404 error on azman/my1ftree\n",
      "404 error on ECNU-Studio/emoc\n",
      "404 error on walterdejong/mpflow\n",
      "404 error on liuzhanjie75/leetcode\n",
      "404 error on PMET-public/magento-scripts\n",
      "404 error on jcsmileyjr/v2-Portfolio404 error on John15321/MUD\n",
      "\n",
      "404 error on XIMDEX/xfind\n",
      "404 error on bmatthias/kolab-android\n",
      "404 error on theSorcerers/octopull\n",
      "404 error on reddress/vertfolia\n",
      "404 error on NoeRamos2/ejemplocss\n",
      "404 error on sonysantos/xgrammar\n",
      "404 error on davidbarratt/davidwbarratt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'download_url'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b03c68c2c1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0masof_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mstatus_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrape_readmes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslugs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mslug_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mreadme_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/brandon_env/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/brandon_env/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/brandon_env/lib/python3.9/site-packages/ratelimit/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRateLimitException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperiod_remaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/brandon_env/lib/python3.9/site-packages/ratelimit/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3c1ecca18203>\u001b[0m in \u001b[0;36mscrape_readmes\u001b[0;34m(slug)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0msite_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mreadme_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'download_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'download_url'"
     ]
    }
   ],
   "source": [
    "# need to change this for each batch or you will save over what you had  \n",
    "batch_name = 'oss_readme_batch_02_01' \n",
    "\n",
    "# sets the number of cores so that it can draw from multiprocessors \n",
    "# there must be 1 core subtracted so that the notebook can run too \n",
    "cores_available = multiprocessing.cpu_count() - 1\n",
    "pool = Pool(cores_available)\n",
    "\n",
    "# convert the dataframe into a list for the subsequent for loop \n",
    "raw_slugs = new_slugs[\"slug\"].tolist()\n",
    "slugs = []\n",
    "for s in raw_slugs:\n",
    "    slugs.append(s.strip())\n",
    "    \n",
    "# now we will feed in all of the remaining slugs \n",
    "slug_log = []\n",
    "readme_log = []\n",
    "asof_log = []\n",
    "status_log = []\n",
    "for result in pool.imap_unordered(scrape_readmes, slugs):\n",
    "    slug_log.append(result[0])\n",
    "    readme_log.append(result[1])\n",
    "    asof_log.append(result[2])\n",
    "    status_log.append(result[3])\n",
    "    final_log = pd.DataFrame({'slug': slug_log, \"readme_text\": readme_log, 'batch': batch_name, 'as_of': asof_log, 'status': status_log}, \n",
    "                              columns=[\"slug\", \"readme_text\", \"batch\", \"as_of\", \"status\"])\n",
    "    final_log.to_csv('/project/class/bii_sdad_dspg/ncses_oss_2021/requests_scrape/'+batch_name+'.csv', sep=',', encoding='utf-8', index=False)\n",
    "print(\"Finished scraping\", len(final_log), \"of\", len(slugs), \"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this chunk is completed, you can go back up and filter out what you just scraped from the dataframe by re-running the \"Checking the Counts\" section and then re-running the \"Scraping the READMEs\" section again. Rinse, cycle, repeat. Feel free to document errors below and don't forget to update the batch number with each cycle.\n",
    "\n",
    "### Common/Known Errors \n",
    "\n",
    "Here are some common/known errors that I have identified: \n",
    "\n",
    "1. `\"MarkupResemblesLocatorWarning: \"{slug}\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.` \n",
    "\n",
    "    Solution: This will just throw a warning and does not seemt to affect subsequent runs of the dataset. You can ignore this. \n",
    "    \n",
    "2. `KeyError: 'download_url'`\n",
    "\n",
    "    Solution: It seems like this error can mean one of two things. The first is insignificant and \n",
    "\n",
    "### Examining the Dataset \n",
    "\n",
    "This code just pulls in all of the downloaded data as a DataFrame and sees how many entries we have downloaded already. You can use the commented line to output all the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>batch</th>\n",
       "      <th>as_of</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h2oota/emacs-win64-msvc</td>\n",
       "      <td>Copyright (C) 2001-2016 Free Software Foundati...</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 17:21</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>CelestiaProject/CelestiaContent</td>\n",
       "      <td>Scientific Data Base\\n--------------------\\n\\n...</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 16:40</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>leanprover-community/mathlib</td>\n",
       "      <td># Lean mathlib\\n\\n![](https://github.com/leanp...</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 16:40</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>adamlaska/osmos-cosmos-sdk</td>\n",
       "      <td># Cosmos SDK\\r\\n\\r\\n![banner](docs/cosmos-sdk-...</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 16:40</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>UniTime/unitime</td>\n",
       "      <td>&lt;!-- \\n * Licensed to The Apereo Foundation un...</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 16:40</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55196</th>\n",
       "      <td>Comparative-Pathology/czi_spatial</td>\n",
       "      <td># czi_spatial\\n\\n[![Build Status](https://trav...</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:37</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55197</th>\n",
       "      <td>nirenjan/x52pro-linux</td>\n",
       "      <td>Saitek X52Pro joystick driver for Linux\\n=====...</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:37</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55198</th>\n",
       "      <td>giftman/Gifts</td>\n",
       "      <td>Gifts\\n====\\n\\n##Test MarkDown\\n`\\n\\npublic vo...</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:35</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55185</th>\n",
       "      <td>xsfelvis/lemon-yang.github.io</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:38</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55871</th>\n",
       "      <td>pghant/big-theta</td>\n",
       "      <td>### The EC2 instance running the Neo4j databas...</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:25</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55872 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    slug  \\\n",
       "0                h2oota/emacs-win64-msvc   \n",
       "462      CelestiaProject/CelestiaContent   \n",
       "463         leanprover-community/mathlib   \n",
       "464           adamlaska/osmos-cosmos-sdk   \n",
       "465                      UniTime/unitime   \n",
       "...                                  ...   \n",
       "55196  Comparative-Pathology/czi_spatial   \n",
       "55197              nirenjan/x52pro-linux   \n",
       "55198                      giftman/Gifts   \n",
       "55185      xsfelvis/lemon-yang.github.io   \n",
       "55871                   pghant/big-theta   \n",
       "\n",
       "                                             readme_text                batch  \\\n",
       "0      Copyright (C) 2001-2016 Free Software Foundati...  oss_readme_batch1_1   \n",
       "462    Scientific Data Base\\n--------------------\\n\\n...  oss_readme_batch1_1   \n",
       "463    # Lean mathlib\\n\\n![](https://github.com/leanp...  oss_readme_batch1_1   \n",
       "464    # Cosmos SDK\\r\\n\\r\\n![banner](docs/cosmos-sdk-...  oss_readme_batch1_1   \n",
       "465    <!-- \\n * Licensed to The Apereo Foundation un...  oss_readme_batch1_1   \n",
       "...                                                  ...                  ...   \n",
       "55196  # czi_spatial\\n\\n[![Build Status](https://trav...  oss_readme_batch1_9   \n",
       "55197  Saitek X52Pro joystick driver for Linux\\n=====...  oss_readme_batch1_9   \n",
       "55198  Gifts\\n====\\n\\n##Test MarkDown\\n`\\n\\npublic vo...  oss_readme_batch1_9   \n",
       "55185                              404 ERROR - NO README  oss_readme_batch1_9   \n",
       "55871  ### The EC2 instance running the Neo4j databas...  oss_readme_batch1_9   \n",
       "\n",
       "                     as_of status  \n",
       "0            6/11/21 17:21   Done  \n",
       "462          6/11/21 16:40   Done  \n",
       "463          6/11/21 16:40   Done  \n",
       "464          6/11/21 16:40   Done  \n",
       "465          6/11/21 16:40   Done  \n",
       "...                    ...    ...  \n",
       "55196  2021-06-14 15:06:37   Done  \n",
       "55197  2021-06-14 15:06:37   Done  \n",
       "55198  2021-06-14 15:06:35   Done  \n",
       "55185  2021-06-14 15:06:38   Done  \n",
       "55871  2021-06-14 15:06:25   Done  \n",
       "\n",
       "[55872 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/project/class/bii_sdad_dspg/ncses_oss_2021/requests_scrape/')\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "combined_csv = combined_csv[combined_csv['status'] == 'Done']\n",
    "combined_csv = combined_csv.sort_values(\"batch\")\n",
    "combined_csv\n",
    "# 21220 > 55872 now \n",
    "#combined_csv.to_csv('/project/class/bii_sdad_dspg/ncses_oss_2021/requests_scrape/oss_readme_aggregated/oss_readme_data_062121.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ That tells you the number of entries we have downloaded. \n",
    "\n",
    "### Development Space \n",
    "\n",
    "Below, are just some snippets of code that might be useful when tweaking the existing code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>batch</th>\n",
       "      <th>as_of</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shahabsaf1/copy</td>\n",
       "      <td># [InfernalTG](https://telegram.me/TeleInferna...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:20:52</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stephan0992/week-1</td>\n",
       "      <td># Jekyll Now\\n\\n**Jekyll** is a static site ge...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:20:52</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynapseProject/handlers.ActiveDirectory.net</td>\n",
       "      <td># handlers.ActiveDirectory.net\\nActive Directo...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:20:52</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mraggi/discreture</td>\n",
       "      <td>[![Build Status](https://travis-ci.org/mraggi/...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:20:52</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>karlstroetmann/Lineare-Algebra</td>\n",
       "      <td>Lineare-Algebra\\n===============\\n\\nIn diesem ...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:20:52</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>pkalro/project8</td>\n",
       "      <td># angular-seed â€” the seed for AngularJS apps...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:35:51</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>Tizzio/WifiTransfer</td>\n",
       "      <td># WifiTransfer\\nDirect wifi file transfer betw...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:35:51</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>PAPARA-ZZ-I/PAPARA-ZZ-I</td>\n",
       "      <td># PAPARA(ZZ)I\\nCopyright 2015-2017 Yann Marcon...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:35:51</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Capital-T-Industries/docker-elk</td>\n",
       "      <td># The ELK stack (Elasticsearch, Logstash, Kiba...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:35:51</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>volpejoaquin/racer</td>\n",
       "      <td>&lt;p align=\"center\"&gt;\\n&lt;a href=\"https://github.co...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:35:51</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2179 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             slug  \\\n",
       "0                                 shahabsaf1/copy   \n",
       "1                              stephan0992/week-1   \n",
       "2     SynapseProject/handlers.ActiveDirectory.net   \n",
       "3                               mraggi/discreture   \n",
       "4                  karlstroetmann/Lineare-Algebra   \n",
       "...                                           ...   \n",
       "2174                              pkalro/project8   \n",
       "2175                          Tizzio/WifiTransfer   \n",
       "2176                      PAPARA-ZZ-I/PAPARA-ZZ-I   \n",
       "2177              Capital-T-Industries/docker-elk   \n",
       "2178                           volpejoaquin/racer   \n",
       "\n",
       "                                            readme_text                batch  \\\n",
       "0     # [InfernalTG](https://telegram.me/TeleInferna...  oss_readme_batch1_8   \n",
       "1     # Jekyll Now\\n\\n**Jekyll** is a static site ge...  oss_readme_batch1_8   \n",
       "2     # handlers.ActiveDirectory.net\\nActive Directo...  oss_readme_batch1_8   \n",
       "3     [![Build Status](https://travis-ci.org/mraggi/...  oss_readme_batch1_8   \n",
       "4     Lineare-Algebra\\n===============\\n\\nIn diesem ...  oss_readme_batch1_8   \n",
       "...                                                 ...                  ...   \n",
       "2174  # angular-seed â€” the seed for AngularJS apps...  oss_readme_batch1_8   \n",
       "2175  # WifiTransfer\\nDirect wifi file transfer betw...  oss_readme_batch1_8   \n",
       "2176  # PAPARA(ZZ)I\\nCopyright 2015-2017 Yann Marcon...  oss_readme_batch1_8   \n",
       "2177  # The ELK stack (Elasticsearch, Logstash, Kiba...  oss_readme_batch1_8   \n",
       "2178  <p align=\"center\">\\n<a href=\"https://github.co...  oss_readme_batch1_8   \n",
       "\n",
       "                    as_of status  \n",
       "0     2021-06-14 12:20:52   Done  \n",
       "1     2021-06-14 12:20:52   Done  \n",
       "2     2021-06-14 12:20:52   Done  \n",
       "3     2021-06-14 12:20:52   Done  \n",
       "4     2021-06-14 12:20:52   Done  \n",
       "...                   ...    ...  \n",
       "2174  2021-06-14 12:35:51   Done  \n",
       "2175  2021-06-14 12:35:51   Done  \n",
       "2176  2021-06-14 12:35:51   Done  \n",
       "2177  2021-06-14 12:35:51   Done  \n",
       "2178  2021-06-14 12:35:51   Done  \n",
       "\n",
       "[2179 rows x 5 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/project/class/bii_sdad_dspg/ncses_oss_2021/requests_scrape/')\n",
    "check = pd.read_csv('oss_readme_batch1_8.csv')\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>batch</th>\n",
       "      <th>as_of</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>g0v-data/mirror-10minutely</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 17:21</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>gregorycv/moodle_quiz_extended</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 17:21</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sisirkoppaka/fluent</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 17:21</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>djbender/homebrew-tmux</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 17:21</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>saidganim/llvm_clone</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_1</td>\n",
       "      <td>6/11/21 17:21</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>King19931229/KApp</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:24</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>tedkulp/phpspec</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:24</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Mad9201/T.M.D</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:23</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>davidjhardman/djh-cms</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:22</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>nh4ar/BESI_besilite</td>\n",
       "      <td>404 ERROR - NO README</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:24</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2573 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               slug            readme_text  \\\n",
       "211      g0v-data/mirror-10minutely  404 ERROR - NO README   \n",
       "301  gregorycv/moodle_quiz_extended  404 ERROR - NO README   \n",
       "49              sisirkoppaka/fluent  404 ERROR - NO README   \n",
       "82           djbender/homebrew-tmux  404 ERROR - NO README   \n",
       "43             saidganim/llvm_clone  404 ERROR - NO README   \n",
       "..                              ...                    ...   \n",
       "278               King19931229/KApp  404 ERROR - NO README   \n",
       "281                 tedkulp/phpspec  404 ERROR - NO README   \n",
       "221                   Mad9201/T.M.D  404 ERROR - NO README   \n",
       "185           davidjhardman/djh-cms  404 ERROR - NO README   \n",
       "254             nh4ar/BESI_besilite  404 ERROR - NO README   \n",
       "\n",
       "                   batch                as_of status  \n",
       "211  oss_readme_batch1_1        6/11/21 17:21   Done  \n",
       "301  oss_readme_batch1_1        6/11/21 17:21   Done  \n",
       "49   oss_readme_batch1_1        6/11/21 17:21   Done  \n",
       "82   oss_readme_batch1_1        6/11/21 17:21   Done  \n",
       "43   oss_readme_batch1_1        6/11/21 17:21   Done  \n",
       "..                   ...                  ...    ...  \n",
       "278  oss_readme_batch1_9  2021-06-14 15:06:24   Done  \n",
       "281  oss_readme_batch1_9  2021-06-14 15:06:24   Done  \n",
       "221  oss_readme_batch1_9  2021-06-14 15:06:23   Done  \n",
       "185  oss_readme_batch1_9  2021-06-14 15:06:22   Done  \n",
       "254  oss_readme_batch1_9  2021-06-14 15:06:24   Done  \n",
       "\n",
       "[2573 rows x 5 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the function from above and make tweaks in this code chunk\n",
    "combined_csv[combined_csv['readme_text'] == \"404 ERROR - NO README\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>batch</th>\n",
       "      <th>as_of</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>flowchain/flowchain-ledger</td>\n",
       "      <td># flowchain-ledger\\n&amp;gt; Flowchain distributed...</td>\n",
       "      <td>oss_readme_batch1_10</td>\n",
       "      <td>2021-06-14 15:15:29</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>fabiocolacio/Mercury</td>\n",
       "      <td># Mercury Chat\\n\\nMercury is my end-to-end enc...</td>\n",
       "      <td>oss_readme_batch1_10</td>\n",
       "      <td>2021-06-14 15:15:38</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>fkbenjamin/pc-firebase-starter</td>\n",
       "      <td># PassChain\\n\\nAuthors: Rob-Jago Flötgen, Flor...</td>\n",
       "      <td>oss_readme_batch1_11</td>\n",
       "      <td>2021-06-14 15:19:18</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>peacedudegregoryks/Old-SBC-SocialBenefitCoin</td>\n",
       "      <td># The Social Benefit Coin Smart contract\\n \\nW...</td>\n",
       "      <td>oss_readme_batch1_11</td>\n",
       "      <td>2021-06-14 15:19:33</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>mukira/fukoblockchainexplorer</td>\n",
       "      <td># Fuko blockchain Explorer\\n\\n![GitHub Logo](h...</td>\n",
       "      <td>oss_readme_batch1_11</td>\n",
       "      <td>2021-06-14 15:19:28</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>agadzinski/vehicle-manufacture-20180607173737101</td>\n",
       "      <td># Blockchain - Tutorial\\n\\nThis is the tutoria...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:35:40</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>shubhamp1p/vehicle-manufacture-20180606135842485</td>\n",
       "      <td># Blockchain - Tutorial\\n\\nThis is the tutoria...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:35:40</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>energywebfoundation/ew-did-registry</td>\n",
       "      <td># EW DID Library v0.1\\n## Disclaimer\\n&amp;gt; The...</td>\n",
       "      <td>oss_readme_batch1_8</td>\n",
       "      <td>2021-06-14 12:20:53</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>jeffet/vehicle-manufacture-20180318192523657</td>\n",
       "      <td># Blockchain - Tutorial\\n\\nThis is the tutoria...</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:23</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>jeffet/vehicle-manufacture-20180318202618486</td>\n",
       "      <td># Blockchain - Tutorial\\n\\nThis is the tutoria...</td>\n",
       "      <td>oss_readme_batch1_9</td>\n",
       "      <td>2021-06-14 15:06:23</td>\n",
       "      <td>Done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  slug  \\\n",
       "449                         flowchain/flowchain-ledger   \n",
       "948                               fabiocolacio/Mercury   \n",
       "254                     fkbenjamin/pc-firebase-starter   \n",
       "1041      peacedudegregoryks/Old-SBC-SocialBenefitCoin   \n",
       "758                      mukira/fukoblockchainexplorer   \n",
       "...                                                ...   \n",
       "1724  agadzinski/vehicle-manufacture-20180607173737101   \n",
       "1689  shubhamp1p/vehicle-manufacture-20180606135842485   \n",
       "33                 energywebfoundation/ew-did-registry   \n",
       "236       jeffet/vehicle-manufacture-20180318192523657   \n",
       "224       jeffet/vehicle-manufacture-20180318202618486   \n",
       "\n",
       "                                            readme_text                 batch  \\\n",
       "449   # flowchain-ledger\\n&gt; Flowchain distributed...  oss_readme_batch1_10   \n",
       "948   # Mercury Chat\\n\\nMercury is my end-to-end enc...  oss_readme_batch1_10   \n",
       "254   # PassChain\\n\\nAuthors: Rob-Jago Flötgen, Flor...  oss_readme_batch1_11   \n",
       "1041  # The Social Benefit Coin Smart contract\\n \\nW...  oss_readme_batch1_11   \n",
       "758   # Fuko blockchain Explorer\\n\\n![GitHub Logo](h...  oss_readme_batch1_11   \n",
       "...                                                 ...                   ...   \n",
       "1724  # Blockchain - Tutorial\\n\\nThis is the tutoria...   oss_readme_batch1_8   \n",
       "1689  # Blockchain - Tutorial\\n\\nThis is the tutoria...   oss_readme_batch1_8   \n",
       "33    # EW DID Library v0.1\\n## Disclaimer\\n&gt; The...   oss_readme_batch1_8   \n",
       "236   # Blockchain - Tutorial\\n\\nThis is the tutoria...   oss_readme_batch1_9   \n",
       "224   # Blockchain - Tutorial\\n\\nThis is the tutoria...   oss_readme_batch1_9   \n",
       "\n",
       "                    as_of status  \n",
       "449   2021-06-14 15:15:29   Done  \n",
       "948   2021-06-14 15:15:38   Done  \n",
       "254   2021-06-14 15:19:18   Done  \n",
       "1041  2021-06-14 15:19:33   Done  \n",
       "758   2021-06-14 15:19:28   Done  \n",
       "...                   ...    ...  \n",
       "1724  2021-06-14 12:35:40   Done  \n",
       "1689  2021-06-14 12:35:40   Done  \n",
       "33    2021-06-14 12:20:53   Done  \n",
       "236   2021-06-14 15:06:23   Done  \n",
       "224   2021-06-14 15:06:23   Done  \n",
       "\n",
       "[124 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_data = combined_csv[combined_csv['readme_text'].notna()]\n",
    "#select_data['readme_clean'] = select_data['readme_text'].str.lower()\n",
    "select_data[select_data['readme_text'].str.contains(\"Blockchain\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to insert updates into sql: https://stackoverflow.com/questions/23103962/how-to-write-dataframe-to-postgres-table\n",
    "multiprocessing: https://stackoverflow.com/questions/45718546/with-clause-for-multiprocessing-in-python/45734483\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brandon_env",
   "language": "python",
   "name": "brandon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
