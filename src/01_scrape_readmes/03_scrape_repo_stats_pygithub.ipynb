{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap repo stats using PyGitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Crystal Zang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilized GitHub access tokens (PAT) to scrape GitHub repository statistics such as stargazers, watchers, forks, and topics. One PAT would scrape at a rate of 5000 repositories per hour. Utilizing 36 PATs we would scrape 10,288,063 repositories in about XXX hours at a rate of 15,514 repositories per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warnings\n",
    "You should not commit any access topen to GitHub, which would result in access token being revoked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages \n",
    "import os\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "import string \n",
    "import json\n",
    "import base64\n",
    "import urllib.request\n",
    "import itertools \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from github import Github, RateLimitExceededException, BadCredentialsException, BadAttributeException, GithubException, UnknownObjectException, BadUserAgentException\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "import multiprocessing\n",
    "#from multiprocessing.pool import ThreadPool as Pool\n",
    "from multiprocessing import Pool, freeze_support\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id        spdx                       slug  \\\n",
      "0  MDEwOlJlcG9zaXRvcnkzMjEzNzQwMg==     GPL-2.0     vlabatut/totalboumboum   \n",
      "1  MDEwOlJlcG9zaXRvcnkxNDU5NDg5NDE=         MIT  Kingzyh/aspnetboilerplate   \n",
      "2  MDEwOlJlcG9zaXRvcnkxOTQ5MzgwNjE=         MIT   NoahBeckerman/GetSquared   \n",
      "3  MDEwOlJlcG9zaXRvcnk5MTA5NDkxNg==  Apache-2.0         jack9603301/thrift   \n",
      "4  MDEwOlJlcG9zaXRvcnkxMjE5NjY1Mzc=         MIT      rsumner31/awesome-ios   \n",
      "\n",
      "            createdat                          description primarylanguage  \\\n",
      "0 2015-03-13 07:05:57  An open source Java Bomberman clone            Java   \n",
      "1 2018-08-24 06:01:38                                 None              C#   \n",
      "2 2019-07-02 21:35:54                Green Squared Exploit           Shell   \n",
      "3 2017-05-12 13:36:08                                 None             C++   \n",
      "4 2018-02-18 16:01:36                                 None            HTML   \n",
      "\n",
      "                                         branch  commits                asof  \\\n",
      "0  MDM6UmVmMzIxMzc0MDI6cmVmcy9oZWFkcy9tYXN0ZXI=     5000 2021-01-03 22:34:53   \n",
      "1  MDM6UmVmMTQ1OTQ4OTQxOnJlZnMvaGVhZHMvbWFzdGVy     5000 2021-01-03 14:10:19   \n",
      "2  MDM6UmVmMTk0OTM4MDYxOnJlZnMvaGVhZHMvbWFzdGVy     5000 2021-01-03 14:11:17   \n",
      "3  MDM6UmVmOTEwOTQ5MTY6cmVmcy9oZWFkcy9tYXN0ZXI=     4999 2021-01-03 13:49:04   \n",
      "4  MDM6UmVmMTIxOTY2NTM3OnJlZnMvaGVhZHMvbWFzdGVy     4999 2021-01-03 22:28:46   \n",
      "\n",
      "  status  \n",
      "0   Init  \n",
      "1   Init  \n",
      "2   Init  \n",
      "3   Init  \n",
      "4   Init  \n",
      "(2284, 10)\n",
      "id                    0\n",
      "spdx                  0\n",
      "slug                  0\n",
      "createdat             0\n",
      "description        1079\n",
      "primarylanguage      15\n",
      "branch                0\n",
      "commits               0\n",
      "asof                  0\n",
      "status                0\n",
      "dtype: int64\n",
      "2284\n",
      "vlabatut/totalboumboum fanaya/angular2_tutorials\n"
     ]
    }
   ],
   "source": [
    "#os.environ['db_user'] = ''\n",
    "#os.environ['db_pwd'] = ''\n",
    "\n",
    "# connect to the database, download data, limit to repos with at least 20,000 commits?\n",
    "connection = pg.connect(host = 'postgis1', database = 'sdad', \n",
    "                        user = os.environ.get('db_user'), \n",
    "                        password = os.environ.get('db_pwd'))\n",
    "\n",
    "raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked WHERE (commits BETWEEN '4500' AND '5000')'''\n",
    "#raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked WHERE commits > 20000'''\n",
    "\n",
    "# convert to a dataframe, show how many missing we have (none)\n",
    "raw_slug_data = pd.read_sql_query(raw_slug_data, con=connection)\n",
    "print(raw_slug_data.head())\n",
    "print(raw_slug_data.shape)\n",
    "print(raw_slug_data.isna().sum())\n",
    "\n",
    "#get rid of leading and ending space, save slugs to a list\n",
    "raw_slugs = raw_slug_data[\"slug\"].tolist()\n",
    "slugs = []\n",
    "for s in raw_slugs:\n",
    "    slugs.append(s.strip())  \n",
    "print(len(slugs))\n",
    "print(slugs[0], slugs[len(slugs)-1])\n",
    "\n",
    "#PATs access token, saved as a dataframe\n",
    "github_pats = '''SELECT * FROM gh_2007_2020.pats_update'''\n",
    "github_pats = pd.read_sql_query(github_pats, con=connection)\n",
    "\n",
    "#PATs access token, saved as a list\n",
    "access_tokens = github_pats[\"token\"]\n",
    "\n",
    "#number of tokens available for use, a numeric value\n",
    "num_token = '''SELECT COUNT(*) FROM gh_2007_2020.pats_update'''\n",
    "num_token = pd.read_sql_query(num_token, con=connection)\n",
    "num_token=num_token.iloc[0]['count']\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index ranges from 0 to maximum number of PATs available\n",
    "def get_access_token(github_pat_index):\n",
    "    if github_pat_index < num_token:\n",
    "       # print(\"Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "        return github_pats.token[github_pat_index]\n",
    "    else:\n",
    "        print(\"token exceed limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#practice slugs\n",
    "slugs_example = [\"moderndive/ModernDive_book\", \"DSPG-Young-Scholars-Program/dspg21oss\", \"rrrrrrrrr\", \"moderndive/ModernDive_book\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(access_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pull_repo_stats(github_pat_index, slugs):\n",
    "    df_repo_stats = pd.DataFrame()\n",
    "    for slug in slugs:\n",
    "        if github_pat_index >= len(access_tokens):\n",
    "            github_pat_index -= len(access_tokens)\n",
    "            print(\"***Pat access token exceed limit, restart access token loop with #\", github_pat_index)\n",
    "        while github_pat_index < len(access_tokens):\n",
    "            try:\n",
    "                access_token = get_access_token(github_pat_index)\n",
    "                #print(\"Scrapping --\", slug,\". Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "                #if false, retry until true, max number of retry is 20 times\n",
    "                g = Github(access_token, retry = 20, timeout = 15)\n",
    "                repo = g.get_repo(slug)\n",
    "                df_repo_stats = df_repo_stats.append({\n",
    "                    \"slug\": slug,\n",
    "                    'stars': repo.stargazers_count,\n",
    "                    'watchers': repo.subscribers_count,\n",
    "                    'forks': repo.forks_count,\n",
    "                    'topics': repo.get_topics()\n",
    "                }, ignore_index = True)\n",
    "            except RateLimitExceededException as e:\n",
    "                print(e.status)\n",
    "                print('Rate limit exceeded --', slug, \", using access token #\", github_pat_index)\n",
    "                print(\"Current time:\", datetime.datetime.now())\n",
    "                #time.sleep(300)\n",
    "                github_pat_index+=1\n",
    "                print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "                break\n",
    "            except BadCredentialsException as e:\n",
    "                print(e.status)\n",
    "                print('Bad credentials exception --', slug, \", using access token #\", github_pat_index)\n",
    "                print(\"Current time:\", datetime.datetime.now())\n",
    "                github_pat_index+=1\n",
    "                print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "                break\n",
    "            except UnknownObjectException as e:\n",
    "                print(e.status)\n",
    "                print('Unknown object exception --', slug)\n",
    "                break\n",
    "            except GithubException as e:\n",
    "                print(e.status)\n",
    "                print('General exception --', slug)\n",
    "                break\n",
    "            except r.exceptions.ConnectionError as e:\n",
    "                print('Retries limit exceeded --', slug)\n",
    "                print(str(e))\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            except r.exceptions.Timeout as e:\n",
    "                print('Time out exception --', slug)\n",
    "                print(str(e))\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            break\n",
    "    return df_repo_stats\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    print(\"Start scraping. Start time:\", datetime.datetime.now())\n",
    "#    pull_repo_stats(github_pat_index=0, slugs = slugs_example)\n",
    "#    print(\"Finish scraping. End time:\", datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to scrape one slug using specified pat index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global github_pat_index\n",
    "def pull_repo_stats(slug, github_pat_index=0):\n",
    "    #github_pat_index = 1\n",
    "   # if github_pat_index >= len(access_tokens):\n",
    "   #     github_pat_index -= len(access_tokens)\n",
    "   #     print(\"***Pat access token exceed limit, restart access token loop with #\", github_pat_index)\n",
    "    while True:\n",
    "        try:\n",
    "            if github_pat_index >= len(access_tokens):\n",
    "                github_pat_index -= len(access_tokens)\n",
    "                print(f\"***Pat access token exceed limit, restart access token loop with #\", github_pat_index)  \n",
    "                \n",
    "            access_token = get_access_token(github_pat_index)\n",
    "            #print(\"Scrapping --\", slug,\". Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "            #if false, retry until true, max number of retry is 20 times\n",
    "            g = Github(access_token, retry = 20, timeout = 15)\n",
    "            repo = g.get_repo(slug)\n",
    "            stars = repo.stargazers_count\n",
    "            watchers = repo.subscribers_count\n",
    "            forks = repo.forks_count\n",
    "            topics = repo.get_topics()\n",
    "        except RateLimitExceededException as e:\n",
    "            print(e.status)\n",
    "            print('WARNING: Rate limit exceeded --', slug, \", using access token #\", github_pat_index)\n",
    "            #time.sleep(300)\n",
    "            github_pat_index+=1\n",
    "            print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "            break\n",
    "        except BadCredentialsException as e:\n",
    "            print(e.status)\n",
    "            print('WARNING: Bad credentials exception --', slug, \", using access token #\", github_pat_index)\n",
    "            github_pat_index+=1\n",
    "            print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "            break\n",
    "        except UnknownObjectException as e:\n",
    "            print(e.status)\n",
    "            print('WARNING: Unknown object exception --', slug)\n",
    "            stars = None\n",
    "            watchers = None\n",
    "            forks =  None\n",
    "            topics = None\n",
    "            return slug, stars, watchers, forks, topics\n",
    "            break\n",
    "        except GithubException as e:\n",
    "            print(e.status)\n",
    "            print('General exception --', slug)\n",
    "            break\n",
    "        except r.exceptions.ConnectionError as e:\n",
    "            print('Retries limit exceeded --', slug)\n",
    "            print(str(e))\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "        except r.exceptions.Timeout as e:\n",
    "            print('Time out exception --', slug)\n",
    "            print(str(e))\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "        return slug, stars, watchers, forks, topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "WARNING: Unknown object exception -- rrrr\n",
      "('rrrr', None, None, None, None)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "result = pull_repo_stats(slug=\"rrrr\")\n",
    "#pull_repo_stats(slug= slugs_example)\n",
    "print(result)\n",
    "#print(result[0])\n",
    "#print(result[1] ==None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing approach: pool.apply_async for multiple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39 CPUs available.\n",
      "Start scraping. Start time: 2021-06-23 11:26:43.117920\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "['moderndive/ModernDive_book', 'DSPG-Young-Scholars-Program/dspg21oss', 'rrrrrrrrr', 'moderndive/ModernDive_book']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/zz3hs/.conda/envs/crystal/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"<ipython-input-33-e1302d689628>\", line 18, in pull_repo_stats\n    repo = g.get_repo(slug)\n  File \"/home/zz3hs/.conda/envs/crystal/lib/python3.7/site-packages/github/MainClass.py\", line 323, in get_repo\n    assert isinstance(full_name_or_id, (str, int)), full_name_or_id\nAssertionError: ['moderndive/ModernDive_book', 'DSPG-Young-Scholars-Program/dspg21oss', 'rrrrrrrrr', 'moderndive/ModernDive_book']\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a0163f9b4231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mslug\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslugs_example\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpull_repo_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslugs_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~~~~~~~~~~~~~~~result: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"~~~~~~~~~~~~~~~~\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/crystal/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ['moderndive/ModernDive_book', 'DSPG-Young-Scholars-Program/dspg21oss', 'rrrrrrrrr', 'moderndive/ModernDive_book']"
     ]
    }
   ],
   "source": [
    "# Approach 2. pool.apply_async for multiple parameters\n",
    "if __name__ == '__main__':\n",
    "    cores_available = multiprocessing.cpu_count() - 1\n",
    "    print(f'There are {cores_available} CPUs available.')\n",
    "    pool = multiprocessing.Pool(cores_available)\n",
    "\n",
    "    # now we will feed in all of the remaining slugs \n",
    "    slug_log = []\n",
    "    stars_log = []\n",
    "    watchers_log = []\n",
    "    forks_log = []\n",
    "    topics_log = []\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"Start scraping. Start time:\", start_time)\n",
    "    \n",
    "    for slug in slugs_example:\n",
    "        result = pool.apply_async(pull_repo_stats, args=(slugs_example, 3)).get()\n",
    "        print(\"~~~~~~~~~~~~~~~result: \",result, \"~~~~~~~~~~~~~~~~\")\n",
    "        if result is None:\n",
    "            slug_log.append(None)\n",
    "            stars_log.append(None)\n",
    "            watchers_log.append(None)\n",
    "            forks_log.append(None)\n",
    "            topics_log.append(None)  \n",
    "        else:\n",
    "            slug_log.append(result[0])\n",
    "            stars_log.append(result[1])\n",
    "            watchers_log.append(result[2])\n",
    "            forks_log.append(result[3])\n",
    "            topics_log.append(result[4])\n",
    "\n",
    "\n",
    "    final_log = pd.DataFrame({'slug': slug_log, \"stars\": stars_log, 'watchers': watchers_log, 'forks': forks_log, 'topics': topics_log}, columns=[\"slug\", \"stars\", \"watchers\", \"forks\", \"topics\"])\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Finished scraping\", len(final_log), \"of\", len(slugs_example), \"records at\", end_time)\n",
    "    print(\"It took\", end_time-start_time, \"to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing approach: pool.imap_unordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39 cores available.\n",
      "404\n",
      "WARNING: Unknown object exception -- rrrrrrrrr\n",
      "Start scraping. Start time: 2021-06-23 11:22:11.104201\n",
      "~~~~~~~~~~~~~~~result:  ('rrrrrrrrr', None, None, None, None) ~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~result:  ('DSPG-Young-Scholars-Program/dspg21oss', 0, 3, 0, []) ~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~result:  ('moderndive/ModernDive_book', 548, 28, 295, ['moderndive', 'data-science', 'tidyverse', 'statistical-inference', 'r', 'ggplot2', 'infer', 'hypothesis-testing', 'confidence-intervals', 'regression', 'regression-models', 'data-visualization', 'data-wrangling', 'tidy', 'rstudio', 'rstats', 'dplyr', 'bootstrap-method', 'permutation-test']) ~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~result:  ('moderndive/ModernDive_book', 548, 28, 295, ['moderndive', 'data-science', 'tidyverse', 'statistical-inference', 'r', 'ggplot2', 'infer', 'hypothesis-testing', 'confidence-intervals', 'regression', 'regression-models', 'data-visualization', 'data-wrangling', 'tidy', 'rstudio', 'rstats', 'dplyr', 'bootstrap-method', 'permutation-test']) ~~~~~~~~~~~~~~~~\n",
      "Finished scraping 4 of 4 records at 2021-06-23 11:22:11.378817\n",
      "It took 0:00:00.274616 to run.\n"
     ]
    }
   ],
   "source": [
    "cores_available = multiprocessing.cpu_count() - 1\n",
    "print(f'There are {cores_available} cores available.')\n",
    "pool = Pool(cores_available)\n",
    "\n",
    "# now we will feed in all of the remaining slugs \n",
    "slug_log = []\n",
    "stars_log = []\n",
    "watchers_log = []\n",
    "forks_log = []\n",
    "topics_log = []\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Start scraping. Start time:\", start_time)\n",
    "for result in pool.imap_unordered(pull_repo_stats, slugs_example):\n",
    "    print(\"~~~~~~~~~~~~~~~result: \",result, \"~~~~~~~~~~~~~~~~\")\n",
    "    if result is None:\n",
    "        slug_log.append(None)\n",
    "        stars_log.append(None)\n",
    "        watchers_log.append(None)\n",
    "        forks_log.append(None)\n",
    "        topics_log.append(None)  \n",
    "    else:\n",
    "        slug_log.append(result[0])\n",
    "        stars_log.append(result[1])\n",
    "        watchers_log.append(result[2])\n",
    "        forks_log.append(result[3])\n",
    "        topics_log.append(result[4])\n",
    "\n",
    "\n",
    "final_log = pd.DataFrame({'slug': slug_log, \"stars\": stars_log, 'watchers': watchers_log, 'forks': forks_log, 'topics': topics_log}, columns=[\"slug\", \"stars\", \"watchers\", \"forks\", \"topics\"])\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"Finished scraping\", len(final_log), \"of\", len(slugs), \"records at\", end_time)\n",
    "print(\"It took\", end_time-start_time, \"to run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>stars</th>\n",
       "      <th>watchers</th>\n",
       "      <th>forks</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rrrrrrrrr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSPG-Young-Scholars-Program/dspg21oss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderndive/ModernDive_book</td>\n",
       "      <td>548.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>[moderndive, data-science, tidyverse, statisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderndive/ModernDive_book</td>\n",
       "      <td>548.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>[moderndive, data-science, tidyverse, statisti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    slug  stars  watchers  forks  \\\n",
       "0                              rrrrrrrrr    NaN       NaN    NaN   \n",
       "1  DSPG-Young-Scholars-Program/dspg21oss    0.0       3.0    0.0   \n",
       "2             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
       "3             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
       "\n",
       "                                              topics  \n",
       "0                                               None  \n",
       "1                                                 []  \n",
       "2  [moderndive, data-science, tidyverse, statisti...  \n",
       "3  [moderndive, data-science, tidyverse, statisti...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_log.to_csv(r'/home/zz3hs/git/dspg21oss/data/dspg21oss/final_log_try.csv', index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    slug  stars  watchers  forks  \\\n",
      "0                              rrrrrrrrr    NaN       NaN    NaN   \n",
      "1  DSPG-Young-Scholars-Program/dspg21oss    0.0       3.0    0.0   \n",
      "2             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "3             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "\n",
      "                                              topics  \n",
      "0                                               None  \n",
      "1                                                 []  \n",
      "2  [moderndive, data-science, tidyverse, statisti...  \n",
      "3  [moderndive, data-science, tidyverse, statisti...  \n",
      "                                    slug  stars  watchers  forks  \\\n",
      "0                              rrrrrrrrr    NaN       NaN    NaN   \n",
      "1  DSPG-Young-Scholars-Program/dspg21oss    0.0       3.0    0.0   \n",
      "2             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "3             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "\n",
      "                                              topics  \n",
      "0                                               None  \n",
      "1                                                 []  \n",
      "2  [moderndive, data-science, tidyverse, statisti...  \n",
      "3  [moderndive, data-science, tidyverse, statisti...  \n",
      "slug        0\n",
      "stars       1\n",
      "watchers    1\n",
      "forks       1\n",
      "topics      1\n",
      "dtype: int64\n",
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "# read in the file and check\n",
    "print(final_log.head())\n",
    "print(final_log)\n",
    "print(final_log.isna().sum())\n",
    "print(final_log.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concactinate scrapped dataframes together\n",
    "df1 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_3000_5000.csv') #import csv\n",
    "print(df1.shape)\n",
    "df2 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_5000_10000.csv') #import csv\n",
    "print(df2.shape)\n",
    "df3 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_10000_11000.csv') #import csv\n",
    "print(df3.shape)\n",
    "df4 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_11000_20000.csv') #import csv\n",
    "print(df4.shape)\n",
    "df5 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_gt_20000.csv') #import csv\n",
    "print(df5.shape)\n",
    "\n",
    "\n",
    "frames = [df1, df2, df3, df4, df5]\n",
    "\n",
    "repo_stats_gt_3000 = pd.concat(frames)\n",
    "print(\"We scrapped\",repo_stats_gt_3000.shape[0], \"repos, that have greater than 3000 commits.\")\n",
    "repo_stats_gt_3000.to_csv(r'/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_gt_3000.csv', index = False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crystal]",
   "language": "python",
   "name": "conda-env-.conda-crystal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
