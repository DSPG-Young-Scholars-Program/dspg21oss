{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap repo stats using PyGitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Crystal Zang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilized GitHub access tokens (PAT) to scrape GitHub repository statistics such as stargazers, watchers, forks, and topics. One PAT would scrape at a rate of 5000 repositories per hour. Utilizing 36 PATs we would scrape 10,288,063 repositories in about XXX hours at a rate of 15,514 repositories per hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warnings\n",
    "You should not commit any access topen to GitHub, which would result in access token being revoked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages \n",
    "import os\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import requests as r\n",
    "import string \n",
    "import json\n",
    "import base64\n",
    "import urllib.request\n",
    "import itertools \n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from github import Github, RateLimitExceededException, BadCredentialsException, BadAttributeException, GithubException, UnknownObjectException, BadUserAgentException\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "import multiprocessing\n",
    "#from multiprocessing.pool import ThreadPool as Pool\n",
    "from multiprocessing import Pool, freeze_support\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id        spdx                   slug  \\\n",
      "0  MDEwOlJlcG9zaXRvcnkzMjQ4MzYxNg==  Apache-2.0          l337ch/kraken   \n",
      "1  MDEwOlJlcG9zaXRvcnkzMDkzNjE2OTM=    AGPL-3.0       iBringit/algo-01   \n",
      "2  MDEwOlJlcG9zaXRvcnkxOTY5NzAxNjE=     GPL-2.0      rma945/CryptoRatt   \n",
      "3  MDEwOlJlcG9zaXRvcnkxMTQ1NTE2NDg=         MIT  mikedennis/FullNodeUI   \n",
      "4  MDEwOlJlcG9zaXRvcnkxMTExODYwODA=         MIT         ignacio-vc/stu   \n",
      "\n",
      "            createdat                                        description  \\\n",
      "0 2015-03-18 20:50:03                                               None   \n",
      "1 2020-11-02 12:22:33                                               None   \n",
      "2 2019-07-15 09:42:38  Password management solution for a DevOps engi...   \n",
      "3 2017-12-17 16:31:51                                               None   \n",
      "4 2017-11-18 07:34:40  Fork of st (simple terminal) by suckless, just...   \n",
      "\n",
      "  primarylanguage                                        branch  commits  \\\n",
      "0             HCL  MDM6UmVmMzI0ODM2MTY6cmVmcy9oZWFkcy9tYXN0ZXI=      999   \n",
      "1            HTML  MDM6UmVmMzA5MzYxNjkzOnJlZnMvaGVhZHMvbWFzdGVy      998   \n",
      "2          Python  MDM6UmVmMTk2OTcwMTYxOnJlZnMvaGVhZHMvbWFzdGVy      998   \n",
      "3             CSS  MDM6UmVmMTE0NTUxNjQ4OnJlZnMvaGVhZHMvbWFzdGVy      998   \n",
      "4               C  MDM6UmVmMTExMTg2MDgwOnJlZnMvaGVhZHMvbWFzdGVy      998   \n",
      "\n",
      "                 asof status  \n",
      "0 2021-01-04 00:15:29   Init  \n",
      "1 2021-01-03 23:16:27   Init  \n",
      "2 2021-01-03 19:18:41   Init  \n",
      "3 2021-01-03 18:16:23   Init  \n",
      "4 2021-01-03 16:48:08   Init  \n",
      "(969, 10)\n",
      "id                   0\n",
      "spdx                 0\n",
      "slug                 0\n",
      "createdat            0\n",
      "description        372\n",
      "primarylanguage      9\n",
      "branch               0\n",
      "commits              0\n",
      "asof                 0\n",
      "status               0\n",
      "dtype: int64\n",
      "969\n",
      "l337ch/kraken postmodern/ruby-install\n"
     ]
    }
   ],
   "source": [
    "#os.environ['db_user'] = ''\n",
    "#os.environ['db_pwd'] = ''\n",
    "\n",
    "# connect to the database, download data, limit to repos with at least 20,000 commits?\n",
    "connection = pg.connect(host = 'postgis1', database = 'sdad', \n",
    "                        user = os.environ.get('db_user'), \n",
    "                        password = os.environ.get('db_pwd'))\n",
    "\n",
    "raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked WHERE (commits BETWEEN '990' AND '1000')'''\n",
    "#raw_slug_data = '''SELECT * FROM gh_2007_2020.repos_ranked WHERE commits < 1000'''\n",
    "\n",
    "# convert to a dataframe, show how many missing we have (none)\n",
    "raw_slug_data = pd.read_sql_query(raw_slug_data, con=connection)\n",
    "print(raw_slug_data.head())\n",
    "print(raw_slug_data.shape)\n",
    "print(raw_slug_data.isna().sum())\n",
    "\n",
    "#get rid of leading and ending space, save slugs to a list\n",
    "raw_slugs = raw_slug_data[\"slug\"].tolist()\n",
    "slugs = []\n",
    "for s in raw_slugs:\n",
    "    slugs.append(s.strip())  \n",
    "print(len(slugs))\n",
    "print(slugs[0], slugs[len(slugs)-1])\n",
    "\n",
    "#PATs access token, saved as a dataframe\n",
    "github_pats = '''SELECT * FROM gh_2007_2020.pats_update'''\n",
    "github_pats = pd.read_sql_query(github_pats, con=connection)\n",
    "\n",
    "#PATs access token, saved as a list\n",
    "access_tokens = github_pats[\"token\"]\n",
    "\n",
    "#number of tokens available for use, a numeric value\n",
    "num_token = '''SELECT COUNT(*) FROM gh_2007_2020.pats_update'''\n",
    "num_token = pd.read_sql_query(num_token, con=connection)\n",
    "num_token=num_token.iloc[0]['count']\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index ranges from 0 to maximum number of PATs available\n",
    "def get_access_token(github_pat_index):\n",
    "    if github_pat_index < num_token:\n",
    "       # print(\"Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "        return github_pats.token[github_pat_index]\n",
    "    else:\n",
    "        print(\"token exceed limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#practice on 7 slugs, one invalid slug \n",
    "slugs_example = [\"moderndive/ModernDive_book\", \"DSPG-Young-Scholars-Program/dspg21oss\", \n",
    "                 \"unknownrepo\", \"moderndive/ModernDive_book\", \"lsst/ip_diffim\", \"esrlabs/chipmunk\", \"paulmillr/chokidar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(access_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not using any multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_repo_stats(github_pat_index, slugs):\n",
    "    df_repo_stats = pd.DataFrame()\n",
    "    for slug in slugs:\n",
    "        if github_pat_index >= len(access_tokens):\n",
    "            github_pat_index -= len(access_tokens)\n",
    "            print(\"***Pat access token exceed limit, restart access token loop with #\", github_pat_index)\n",
    "        while github_pat_index < len(access_tokens):\n",
    "            try:\n",
    "                access_token = get_access_token(github_pat_index)\n",
    "                #print(\"Scrapping --\", slug,\". Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "                #if false, retry until true, max number of retry is 20 times\n",
    "                g = Github(access_token, retry = 20, timeout = 15)\n",
    "                repo = g.get_repo(slug)\n",
    "                df_repo_stats = df_repo_stats.append({\n",
    "                    \"slug\": slug,\n",
    "                    'stars': repo.stargazers_count,\n",
    "                    'watchers': repo.subscribers_count,\n",
    "                    'forks': repo.forks_count,\n",
    "                    'topics': repo.get_topics()\n",
    "                }, ignore_index = True)\n",
    "            except RateLimitExceededException as e:\n",
    "                print(e.status)\n",
    "                print('Rate limit exceeded --', slug, \", using access token #\", github_pat_index)\n",
    "                print(\"Current time:\", datetime.datetime.now())\n",
    "                #time.sleep(300)\n",
    "                github_pat_index+=1\n",
    "                print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "                break\n",
    "            except BadCredentialsException as e:\n",
    "                print(e.status)\n",
    "                print('Bad credentials exception --', slug, \", using access token #\", github_pat_index)\n",
    "                print(\"Current time:\", datetime.datetime.now())\n",
    "                github_pat_index+=1\n",
    "                print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "                break\n",
    "            except UnknownObjectException as e:\n",
    "                print(e.status)\n",
    "                print('Unknown object exception --', slug)\n",
    "                break\n",
    "            except GithubException as e:\n",
    "                print(e.status)\n",
    "                print('General exception --', slug)\n",
    "                break\n",
    "            except r.exceptions.ConnectionError as e:\n",
    "                print('Retries limit exceeded --', slug)\n",
    "                print(str(e))\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            except r.exceptions.Timeout as e:\n",
    "                print('Time out exception --', slug)\n",
    "                print(str(e))\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            break\n",
    "    return df_repo_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start scraping:\", start_time)\n",
    "df_repo_stats = pull_repo_stats(0, slugs)\n",
    "end_time =  datetime.datetime.now()\n",
    "print(\"Finished scraping\", len(df_repo_stats), \"of\", len(slugs), \"records at\", end_time)\n",
    "print(\"It took\", end_time-start_time, \"to run.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# read in the file and check\n",
    "df_repo_stats.head()\n",
    "#print(df_repo_stats)\n",
    "#print(df_repo_stats.isna().sum())\n",
    "#print(df_repo_stats.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_repo_stats.to_csv(r'/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_1000_1500.csv', index = False)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to scrape one slug using specified pat index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global github_pat_index\n",
    "def pull_repo_stats(slug, github_pat_index):\n",
    "    #github_pat_index = 1\n",
    "   # if github_pat_index >= len(access_tokens):\n",
    "   #     github_pat_index -= len(access_tokens)\n",
    "   #     print(\"***Pat access token exceed limit, restart access token loop with #\", github_pat_index)\n",
    "    while True:\n",
    "        try:\n",
    "            if github_pat_index >= len(access_tokens):\n",
    "                github_pat_index -= len(access_tokens)\n",
    "                print(f\"***Pat access token exceed limit, restart access token loop with #\", github_pat_index)  \n",
    "                \n",
    "            access_token = get_access_token(github_pat_index)\n",
    "            #print(\"Scrapping --\", slug,\". Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\n",
    "            #if false, retry until true, max number of retry is set to 3 times\n",
    "            g = Github(access_token, retry = 3, timeout = 15)\n",
    "            repo = g.get_repo(slug)\n",
    "            stars = repo.stargazers_count\n",
    "            watchers = repo.subscribers_count\n",
    "            forks = repo.forks_count\n",
    "            topics = repo.get_topics()\n",
    "        except RateLimitExceededException as e:\n",
    "            print(e.status)\n",
    "            print('WARNING: Rate limit exceeded --', slug, \", using access token #\", github_pat_index)\n",
    "            #time.sleep(300)\n",
    "            github_pat_index+=1\n",
    "            print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "            break\n",
    "        except BadCredentialsException as e:\n",
    "            print(e.status)\n",
    "            print('WARNING: Bad credentials exception --', slug, \", using access token #\", github_pat_index)\n",
    "            github_pat_index+=1\n",
    "            print(\"***Exit current access token, proceed with next aceess token #\", github_pat_index, \"rescrape --\",slug)\n",
    "            break\n",
    "        except UnknownObjectException as e:\n",
    "            print(e.status)\n",
    "            print('WARNING: Unknown object exception --', slug)\n",
    "            stars = None\n",
    "            watchers = None\n",
    "            forks =  None\n",
    "            topics = None\n",
    "            return slug, stars, watchers, forks, topics\n",
    "            break\n",
    "        except GithubException as e:\n",
    "            print(e.status)\n",
    "            print('General exception --', slug)\n",
    "            break\n",
    "        except r.exceptions.ConnectionError as e:\n",
    "            print('Retries limit exceeded --', slug)\n",
    "            print(str(e))\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "        except r.exceptions.Timeout as e:\n",
    "            print('Time out exception --', slug)\n",
    "            print(str(e))\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "            \n",
    "        results = (slug, stars, watchers, forks, topics)\n",
    "        #return slug, stars, watchers, forks, topics\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moderndive/ModernDive_book\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_access_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-f3dd08f162ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslugs_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_repo_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslugs_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-142-8be357da3c4e>\u001b[0m in \u001b[0;36mpull_repo_stats\u001b[0;34m(slug, github_pat_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"***Pat access token exceed limit, restart access token loop with #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgithub_pat_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0maccess_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub_pat_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m#print(\"Scrapping --\", slug,\". Extracting access token #\", github_pat_index+1,\", total\", num_token, \"tokens are available.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#if false, retry until true, max number of retry is set to 3 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_access_token' is not defined"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "i = 0\n",
    "print(slugs_example[i])\n",
    "result = pull_repo_stats(slugs_example[i], 0)\n",
    "print(result[3])\n",
    "\n",
    "#print(result[0])\n",
    "#print(result[1] ==None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing approach: pool.apply_async for multiple parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(results):\n",
    "    global slug_log\n",
    "    global stars_log\n",
    "    global watchers_log\n",
    "    global forks_log\n",
    "    global topics_log\n",
    "    if result is None:\n",
    "        slug_log.append(None)\n",
    "        stars_log.append(None)\n",
    "        watchers_log.append(None)\n",
    "        forks_log.append(None)\n",
    "        topics_log.append(None)  \n",
    "    else:\n",
    "        slug_log.append(results[0])\n",
    "        stars_log.append(results[1])\n",
    "        watchers_log.append(results[2])\n",
    "        forks_log.append(results[3])\n",
    "        topics_log.append(results[4])\n",
    "        #print(\"appending results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stars(stars):\n",
    "    global stars_log\n",
    "    stars_log.append(stars)\n",
    "    print(\"appending results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_log = []\n",
    "#practice on 2 slugs, one invalid slug \n",
    "#slugs_example = [\"moderndive/ModernDive_book\", \"unknownrepo\"]\n",
    "\n",
    "#practice on 7 slugs, one invalid slug \n",
    "slugs_example = [\"moderndive/ModernDive_book\", \"DSPG-Young-Scholars-Program/dspg21oss\", \n",
    "                 \"unknownrepo\", \"moderndive/ModernDive_book\", \"lsst/ip_diffim\", \"esrlabs/chipmunk\", \"paulmillr/chokidar\"]\n",
    "\n",
    "\n",
    "slugs_100 = slugs[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39 CPUs available.\n",
      "Start scraping. Start time: 2021-06-24 16:53:54.715233\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'github_pat_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-ac6a56678ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#result = pool.apply_async(pull_repo_stats, args=(slugs_example, 3)).get()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~~~~~~~~~~~~~~~slug: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"using access token #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgithub_pat_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"~~~~~~~~~~~~~~~~\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#if result is None:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m          \u001b[0;31m#   slug_log.append(None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'github_pat_index' is not defined"
     ]
    }
   ],
   "source": [
    "# Approach 2. pool.apply_async for multiple parameters\n",
    "if __name__ == '__main__':\n",
    "    cores_available = multiprocessing.cpu_count() - 1\n",
    "    print(f'There are {cores_available} CPUs available.')\n",
    "    #pool = multiprocessing.Pool(cores_available)\n",
    "    pool = multiprocessing.Pool(4)\n",
    "    \n",
    "    # now we will feed in all of the remaining slugs \n",
    "    slug_log = []\n",
    "    stars_log = []\n",
    "    watchers_log = []\n",
    "    forks_log = []\n",
    "    topics_log = []\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"Start scraping. Start time:\", start_time)\n",
    "    \n",
    "    for slug in slugs:\n",
    "        #get_result(pull_repo_stats(slug, 0))\n",
    "        \n",
    "        pool.apply_async(pull_repo_stats, args=(slug,  3),callback = get_result)\n",
    "        #result = pool.apply_async(pull_repo_stats, args=(slugs_example, 3)).get()\n",
    "        \n",
    "        print(\"~~~~~~~~~~~~~~~slug: \",slug, \"using access token #\", github_pat_index, \"~~~~~~~~~~~~~~~~\")\n",
    "        #if result is None:\n",
    "         #   slug_log.append(None)\n",
    "         #   stars_log.append(None)\n",
    "         #   watchers_log.append(None)\n",
    "         #   forks_log.append(None)\n",
    "         #   topics_log.append(None)  \n",
    "        #else:\n",
    "         #   slug_log.append(result[0])\n",
    "         #   stars_log.append(result[1])\n",
    "         #   watchers_log.append(result[2])\n",
    "         #   forks_log.append(result[3])\n",
    "         #   topics_log.append(result[4])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    final_log = pd.DataFrame({'slug': slug_log, \"stars\": stars_log, 'watchers': watchers_log, 'forks': forks_log, 'topics': topics_log}, columns=[\"slug\", \"stars\", \"watchers\", \"forks\", \"topics\"])\n",
    "\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"Finished scraping\", len(final_log), \"of\", len(slugs_example), \"records at\", end_time)\n",
    "    print(\"It took\", end_time-start_time, \"to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>stars</th>\n",
       "      <th>watchers</th>\n",
       "      <th>forks</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknownrepo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderndive/ModernDive_book</td>\n",
       "      <td>548.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>[moderndive, data-science, tidyverse, statisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderndive/ModernDive_book</td>\n",
       "      <td>548.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>[moderndive, data-science, tidyverse, statisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DSPG-Young-Scholars-Program/dspg21oss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsst/ip_diffim</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>esrlabs/chipmunk</td>\n",
       "      <td>285.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[logs-analysis, logviewer, search, logstash, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>paulmillr/chokidar</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>[watch-files, fsevents, watcher, filesystem]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    slug   stars  watchers  forks  \\\n",
       "0                            unknownrepo     NaN       NaN    NaN   \n",
       "1             moderndive/ModernDive_book   548.0      28.0  295.0   \n",
       "2             moderndive/ModernDive_book   548.0      28.0  295.0   \n",
       "3  DSPG-Young-Scholars-Program/dspg21oss     0.0       3.0    0.0   \n",
       "4                         lsst/ip_diffim     5.0      45.0    7.0   \n",
       "5                       esrlabs/chipmunk   285.0      11.0   23.0   \n",
       "6                     paulmillr/chokidar  7990.0      85.0  511.0   \n",
       "\n",
       "                                              topics  \n",
       "0                                               None  \n",
       "1  [moderndive, data-science, tidyverse, statisti...  \n",
       "2  [moderndive, data-science, tidyverse, statisti...  \n",
       "3                                                 []  \n",
       "4                                                 []  \n",
       "5  [logs-analysis, logviewer, search, logstash, l...  \n",
       "6       [watch-files, fsevents, watcher, filesystem]  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(final_log)\n",
    "final_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing approach: pool.imap_unordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39 cores available.\n",
      "404\n",
      "WARNING: Unknown object exception -- rrrrrrrrr\n",
      "Start scraping. Start time: 2021-06-23 11:22:11.104201\n",
      "~~~~~~~~~~~~~~~result:  ('rrrrrrrrr', None, None, None, None) ~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~result:  ('DSPG-Young-Scholars-Program/dspg21oss', 0, 3, 0, []) ~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~result:  ('moderndive/ModernDive_book', 548, 28, 295, ['moderndive', 'data-science', 'tidyverse', 'statistical-inference', 'r', 'ggplot2', 'infer', 'hypothesis-testing', 'confidence-intervals', 'regression', 'regression-models', 'data-visualization', 'data-wrangling', 'tidy', 'rstudio', 'rstats', 'dplyr', 'bootstrap-method', 'permutation-test']) ~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~result:  ('moderndive/ModernDive_book', 548, 28, 295, ['moderndive', 'data-science', 'tidyverse', 'statistical-inference', 'r', 'ggplot2', 'infer', 'hypothesis-testing', 'confidence-intervals', 'regression', 'regression-models', 'data-visualization', 'data-wrangling', 'tidy', 'rstudio', 'rstats', 'dplyr', 'bootstrap-method', 'permutation-test']) ~~~~~~~~~~~~~~~~\n",
      "Finished scraping 4 of 4 records at 2021-06-23 11:22:11.378817\n",
      "It took 0:00:00.274616 to run.\n"
     ]
    }
   ],
   "source": [
    "cores_available = multiprocessing.cpu_count() - 1\n",
    "print(f'There are {cores_available} cores available.')\n",
    "pool = Pool(cores_available)\n",
    "\n",
    "# now we will feed in all of the remaining slugs \n",
    "slug_log = []\n",
    "stars_log = []\n",
    "watchers_log = []\n",
    "forks_log = []\n",
    "topics_log = []\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Start scraping. Start time:\", start_time)\n",
    "for result in pool.imap_unordered(pull_repo_stats, slugs_example):\n",
    "    print(\"~~~~~~~~~~~~~~~result: \",result, \"~~~~~~~~~~~~~~~~\")\n",
    "    if result is None:\n",
    "        slug_log.append(None)\n",
    "        stars_log.append(None)\n",
    "        watchers_log.append(None)\n",
    "        forks_log.append(None)\n",
    "        topics_log.append(None)  \n",
    "    else:\n",
    "        slug_log.append(result[0])\n",
    "        stars_log.append(result[1])\n",
    "        watchers_log.append(result[2])\n",
    "        forks_log.append(result[3])\n",
    "        topics_log.append(result[4])\n",
    "\n",
    "\n",
    "final_log = pd.DataFrame({'slug': slug_log, \"stars\": stars_log, 'watchers': watchers_log, 'forks': forks_log, 'topics': topics_log}, columns=[\"slug\", \"stars\", \"watchers\", \"forks\", \"topics\"])\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"Finished scraping\", len(final_log), \"of\", len(slugs), \"records at\", end_time)\n",
    "print(\"It took\", end_time-start_time, \"to run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>stars</th>\n",
       "      <th>watchers</th>\n",
       "      <th>forks</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rrrrrrrrr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSPG-Young-Scholars-Program/dspg21oss</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderndive/ModernDive_book</td>\n",
       "      <td>548.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>[moderndive, data-science, tidyverse, statisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderndive/ModernDive_book</td>\n",
       "      <td>548.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>[moderndive, data-science, tidyverse, statisti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    slug  stars  watchers  forks  \\\n",
       "0                              rrrrrrrrr    NaN       NaN    NaN   \n",
       "1  DSPG-Young-Scholars-Program/dspg21oss    0.0       3.0    0.0   \n",
       "2             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
       "3             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
       "\n",
       "                                              topics  \n",
       "0                                               None  \n",
       "1                                                 []  \n",
       "2  [moderndive, data-science, tidyverse, statisti...  \n",
       "3  [moderndive, data-science, tidyverse, statisti...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_log.to_csv(r'/home/zz3hs/git/dspg21oss/data/dspg21oss/final_log_try.csv', index = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    slug  stars  watchers  forks  \\\n",
      "0                              rrrrrrrrr    NaN       NaN    NaN   \n",
      "1  DSPG-Young-Scholars-Program/dspg21oss    0.0       3.0    0.0   \n",
      "2             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "3             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "\n",
      "                                              topics  \n",
      "0                                               None  \n",
      "1                                                 []  \n",
      "2  [moderndive, data-science, tidyverse, statisti...  \n",
      "3  [moderndive, data-science, tidyverse, statisti...  \n",
      "                                    slug  stars  watchers  forks  \\\n",
      "0                              rrrrrrrrr    NaN       NaN    NaN   \n",
      "1  DSPG-Young-Scholars-Program/dspg21oss    0.0       3.0    0.0   \n",
      "2             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "3             moderndive/ModernDive_book  548.0      28.0  295.0   \n",
      "\n",
      "                                              topics  \n",
      "0                                               None  \n",
      "1                                                 []  \n",
      "2  [moderndive, data-science, tidyverse, statisti...  \n",
      "3  [moderndive, data-science, tidyverse, statisti...  \n",
      "slug        0\n",
      "stars       1\n",
      "watchers    1\n",
      "forks       1\n",
      "topics      1\n",
      "dtype: int64\n",
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "# read in the file and check\n",
    "print(final_log.head())\n",
    "print(final_log)\n",
    "print(final_log.isna().sum())\n",
    "print(final_log.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concactinate scrapped dataframes together\n",
    "df1 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_1000_1500.csv') #import csv\n",
    "print(df1.shape)\n",
    "df2 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_1500_2000.csv') #import csv\n",
    "print(df2.shape)\n",
    "df3 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_bt_2000_4500.csv') #import csv\n",
    "print(df3.shape)\n",
    "df4 = pd.read_csv('/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_gt_3000.csv') #import csv\n",
    "print(df4.shape)\n",
    "\n",
    "\n",
    "frames = [df1, df2, df3, df4]\n",
    "\n",
    "repo_stats_gt_1000 = pd.concat(frames)\n",
    "\n",
    "repo_stats_gt_1000 = repo_stats_gt_1000.drop_duplicates(subset = 'slug', keep = 'first')\n",
    "print(\"We scrapped\",repo_stats_gt_1000.shape[0], \"repos, that have greater than 1000 commits.\")\n",
    "\n",
    "#repo_stats_gt_3000.to_csv(r'/home/zz3hs/git/dspg21oss/data/dspg21oss/repo_stats_gt_3000.csv', index = False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-crystal]",
   "language": "python",
   "name": "conda-env-.conda-crystal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
